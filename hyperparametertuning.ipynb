{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "while i<=10:\n",
    "    print('hello')\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "i=10\n",
    "while i>=1:\n",
    "    print('hello')\n",
    "    i=i-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 1\n",
      "hello 2\n",
      "hello 3\n",
      "hello 4\n",
      "hello 5\n",
      "hello 6\n",
      "hello 7\n",
      "hello 8\n",
      "hello 9\n",
      "hello 10\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "while i<=10:\n",
    "    print('hello',i)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello ind ind ind ind \n",
      "hello ind ind ind ind \n",
      "hello ind ind ind ind \n",
      "hello ind ind ind ind \n",
      "hello ind ind ind ind \n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "while i<=5:\n",
    "    print('hello ',end=\"\")\n",
    "    \n",
    "    j=1\n",
    "    while j<=4:\n",
    "        print('ind ',end=\"\")\n",
    "        j=j+1\n",
    "        \n",
    "    i=i+1\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hkr\n",
      "10\n",
      "20.3\n"
     ]
    }
   ],
   "source": [
    "# for loop\n",
    "val=['hkr',10,20.3]\n",
    "for i in val:\n",
    "    print(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many candy u want?10\n",
      "candy\n",
      "candy\n",
      "candy\n",
      "candy\n",
      "candy\n"
     ]
    }
   ],
   "source": [
    "# break\n",
    "x=int(input(\"how many candy u want?\"))\n",
    "avg=5\n",
    "\n",
    "i=1\n",
    "while i<=x:\n",
    "    \n",
    "    if i>avg:\n",
    "        break\n",
    "        \n",
    "    print('candy')\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many candy u want?10\n",
      "candy\n",
      "candy\n",
      "candy\n",
      "candy\n",
      "candy\n",
      "out of stock\n"
     ]
    }
   ],
   "source": [
    "x=int(input(\"how many candy u want?\"))\n",
    "avg=5\n",
    "\n",
    "i=1\n",
    "while i<=x:\n",
    "    \n",
    "    if i>avg:\n",
    "        print('out of stock')\n",
    "        break\n",
    "        \n",
    "    print('candy')\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many candy u want?10\n",
      "out of stock\n"
     ]
    }
   ],
   "source": [
    "x=int(input(\"how many candy u want?\"))\n",
    "avg=5\n",
    "\n",
    "i=1\n",
    "while i<=x:\n",
    "    \n",
    "    if i>avg:\n",
    "        print('out of stock')\n",
    "        break\n",
    "        \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('E:\\\\python\\\\csv files\\\\titanic csv\\\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x956204ba8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.boxplot(x=\"Pclass\",y=\"Age\",data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x9575995c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "sns.boxplot(x=\"Pclass\",y=\"Age\",data=train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    1\n",
       "2    3\n",
       "3    1\n",
       "4    3\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Pclass'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22.0\n",
       "1    38.0\n",
       "2    26.0\n",
       "3    35.0\n",
       "4    35.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Age'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x957626c88>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train['Age'].dropna(),kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x9576a4b38>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEECAYAAAA4Qc+SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAW4UlEQVR4nO3df2wT9/3H8ZcTE0N+QZNohSlNlRQQ4Ysm1qIAUxqYNkjp1v3o6PghhVZsU2G0NKzQBEoICFagTGwd0wasm9ASWFdaNnVbp61QaSm/MlQBHZE3RFulSnC6QVKan/Y5vu8fiHQVxMEXO3Y+eT7+Ijbvu5cu5uXjfHd22bZtCwAw7CXFOwAAIDoodAAwBIUOAIag0AHAEBQ6ABjCHc+Vnzt3Th6PJ6IZv98f8cxQSdRs5IpMouaSEjcbuSIz2Fx+v1/Tp0+/6fG4FrrH41FhYWFEM16vN+KZoZKo2cgVmUTNJSVuNnJFZrC5vF7vLR/nkAsAGIJCBwBD3Fahnz9/XmVlZZKkxsZGLVmyREuXLlV1dbVCoZAk6Wc/+5kWLlyoxYsX65133oldYgDALQ1Y6L/85S+1ceNG+f1+SdL27dtVXl6uQ4cOybZtHTt2TA0NDfrHP/6hw4cPa/fu3dqyZUvMgwMAPm3AD0Xz8vK0Z88ePfPMM5KkhoYGFRUVSZJKSkp04sQJ5efnq7i4WC6XS5/97GfV29ur1tZWZWVlhV223+/v9+B+f3p6eiKeGSqJmo1ckUnUXFLiZiNXZGKVa8BCLy0tVVNTU9/Ptm3L5XJJktLS0tTe3q6Ojg6NGzeu7+/ceHygQucsl6FBrsgkai4pcbORKzIJc5ZLUtInI52dncrMzFR6ero6Ozs/9XhGRoaDmAAApyIu9KlTp6q+vl6SVFdXpxkzZujee+/V8ePHFQqFdPnyZYVCoQH3zgEA0RXxhUUVFRWqqqrS7t27VVBQoNLSUiUnJ2vGjBlatGiRQqGQNm3aFIusAIAwbqvQc3Nz9fLLL0uS8vPzVVtbe9PfefLJJ/Xkk09GNx2i5lpXQO3+oKPZDI9bY1NTopwIQLTF9dJ/DJ12f1B1F684mi2ZnEOhA8MAV4oCgCEodAAwBIUOAIag0AHAEBQ6ABiCQgcAQ1DoAGAICh0ADEGhA4AhKHQAMASFDgCGoNABwBAUOgAYgkIHAENQ6ABgCAodAAxBoQOAISh0ADAEhQ4AhqDQAcAQFDoAGIJCBwBDUOgAYAgKHQAMQaEDgCHc8Q6AxBfsDamprcvxfIbHrbGpKVFMBOBWKHQMqNsK6ey7rY7nSybnUOjAEKDQEXP97eEH3OkD7vmzdw/cPgodMdffHr6vxacJ4+2ws+zdA7ePD0UBwBAUOgAYgkIHAENQ6ABgCEcfilqWpcrKSjU3NyspKUlbt26V2+1WZWWlXC6XJk2apOrqaiUl8X4BAEPFUaH//e9/VzAY1EsvvaQTJ07oJz/5iSzLUnl5uWbOnKlNmzbp2LFjmjdvXrTzAgD64WgXOj8/X729vQqFQuro6JDb7VZDQ4OKiookSSUlJTp58mRUgwIAwnO0h56amqrm5mYtWLBAbW1t2rt3r86cOSOXyyVJSktLU3t7+4DL8fv98nq9Ea27p6cn4pmhkqjZenp6FLhyVb4Wn6P5KTkpjmfDzQcta8DlXs1yqb2l0fG6nUjU36OUuNnIFZlY5XJU6AcOHFBxcbGefvpp+Xw+Pfroo7Isq+/5zs5OZWZmDrgcj8ejwsLCiNbt9XojnhkqiZrN6/UqIyd7wIt4+jMmNVUTxk9wvP7+5q9fWBR+udk52cq94y7H63YiUX+PUuJmI1dkBpurvzcDR4WemZmpUaNGSZLGjh2rYDCoqVOnqr6+XjNnzlRdXZ1mzZrlOCxu7VpXQO3+YMRzAXe6/FZvDBIBSCSOCv2xxx7Thg0btHTpUlmWpTVr1mjatGmqqqrS7t27VVBQoNLS0mhnHfHa/UHVXbwS8ZyvxacHi8bGIBGAROKo0NPS0vTCCy/c9Hhtbe2gAwEAnOFEcQAwBIUOAIag0AHAEBQ6ABiCQgcAQ1DoAGAICh0ADEGhA4AhKHQAMASFDgCGcHTpPzBUgr0hNbV1OZrN8Lg1NjUlyomAxEWhI6F1WyGdfbfV0WzJ5BwKHSMKh1wAwBAUOgAYgkIHAENQ6ABgCAodAAxBoQOAISh0ADAEhQ4AhqDQAcAQFDoAGIJCBwBDUOgAYAgKHQAMQaEDgCEodAAwBIUOAIag0AHAEBQ6ABiCQgcAQ1DoAGAICh0ADEGhA4Ah3E4H9+3bpzfffFOWZWnJkiUqKipSZWWlXC6XJk2apOrqaiUl8X4BAEPFUePW19fr7Nmz+u1vf6uamhq1tLRo+/btKi8v16FDh2Tbto4dOxbtrACAMBwV+vHjxzV58mStWrVKK1as0Ny5c9XQ0KCioiJJUklJiU6ePBnVoACA8Bwdcmlra9Ply5e1d+9eNTU1aeXKlbJtWy6XS5KUlpam9vb2AZfj9/vl9XojWndPT0/EM0Ml1tkC7nT5WnwRzwUtS91dXY5mJWlKTorj2XDzQcsacLmDWffVLJfaWxojnhvJrzGnyBWZWOVyVOjjxo1TQUGBUlJSVFBQII/Ho5aWlr7nOzs7lZmZOeByPB6PCgsLI1q31+uNeGaoxDpbU1uXJoy3I57ztfg0JjVVE8ZPcLTewcyGm/e1+AZc7mDWnZ2Trdw77op4biS/xpwiV2QGm6u/NwNHh1zuu+8+vfXWW7JtWx9++KG6u7s1e/Zs1dfXS5Lq6uo0Y8YMx2EBAJFztIf+xS9+UWfOnNHChQtl27Y2bdqk3NxcVVVVaffu3SooKFBpaWm0swIAwnB82uIzzzxz02O1tbWDCgMAcI4TxQHAEBQ6ABiCQgcAQ1DoAGAICh0ADEGhA4AhKHQAMASFDgCGoNABwBAUOgAYgkIHAENQ6ABgCAodAAxBoQOAISh0ADAEhQ4AhqDQAcAQFDoAGIJCBwBDUOgAYAgKHQAMQaEDgCEodAAwBIUOAIag0AHAEBQ6ABiCQgcAQ7jjHQCIlWBvSE1tXRHPBdzputYV0NjUlBikAmKHQoexuq2Qzr7bGvGcr8WnRTnZFDqGHQ65AIAhKHQAMASFDgCGoNABwBAUOgAYgkIHAEMMqtCvXr2qOXPm6N1331VjY6OWLFmipUuXqrq6WqFQKFoZAQC3wXGhW5alTZs2afTo0ZKk7du3q7y8XIcOHZJt2zp27FjUQgIABub4wqKdO3dq8eLF2r9/vySpoaFBRUVFkqSSkhKdOHFC8+bNC7sMv98vr9cb0Xp7enrk9XqV5ElTT6/LUfbRybZC/k5Hs+HcyBYrAXe6fC2+iOeClqXuri5Hs5I0JSfF8Wy4+aBlDbjcwazb6WzQsnT1ylW1tzQ6Wm8sxfo15hS5IhOrXI4K/ciRI8rKytL999/fV+i2bcvlul6waWlpam9vH3A5Ho9HhYWFEa3b6/WqsLBQTW1devvilcjDSyqZnKPcO/IczYZzI1usNLV1acJ4O+I5X4tPY1JTNWH8BEfrHcxsuHlfi2/A5cYjt6/Fp+ycbOXecZej9cZSrF9jTpErMoPN1d+bgaNCf/XVV+VyuXTq1Cl5vV5VVFSotfWTS6w7OzuVmZnpLCkAwBFHhX7w4MG+P5eVlWnz5s3atWuX6uvrNXPmTNXV1WnWrFlRCwkAGFjUTlusqKjQnj17tGjRIlmWpdLS0mgtGgBwGwZ9t8Wampq+P9fW1g52cQAAh7iwCAAMQaEDgCEodAAwBIUOAIag0AHAEHynKHALTr9gWpLcSVJwEPemy/C4+T5TOEKhA7fg9AumJenzeeN09oOPHK+7ZHIOhQ5HOOQCAIag0AHAEBQ6ABiCQgcAQ1DoAGAICh0ADMFpi0PsWldA7f6go1m/1RvlNABMQqEPsXZ/UHUOvzrv83njopwGgEk45AIAhqDQAcAQFDoAGIJj6ECCCXdjsIA7PexNw7ix18hGoQMJJtyNwXwtPk0Yb/c7y429RjYOuQCAISh0ADAEhQ4AhqDQAcAQFDoAGIJCBwBDUOgAYAgKHQAMQaEDgCEodAAwBIUOAIag0AHAEBQ6ABiCQgcAQzi6fa5lWdqwYYOam5sVCAS0cuVKTZw4UZWVlXK5XJo0aZKqq6uVlMT7BQAMFUeF/tprr2ncuHHatWuX2tra9M1vflNTpkxReXm5Zs6cqU2bNunYsWOaN29etPMCAPrhaBf6gQce0FNPPdX3c3JyshoaGlRUVCRJKikp0cmTJ6OTEABwWxztoaelpUmSOjo6tHr1apWXl2vnzp1yuVx9z7e3tw+4HL/fL6/XG9G6e3p65PV6FXCny9fiizy8pKtZLrW3NDqaDedGtnAGk3tKToqj2aBlqbura8jXO9B80LIGXO5g1m3a9rqRLdyyY/XaHsjtvPbjYaTlcvwVdD6fT6tWrdLSpUv10EMPadeuXX3PdXZ2KjMzc8BleDweFRYWRrRer9erwsJCNbV1hf0qrnCyc7KVe8ddjmbDuZEtnMHkHpOaqgnjJ0Q852vxOZ4dzHoHmr/+dWrhlxuP3Im6vW5kC7fsWL22B3I7r/14MDVXf28Gjg65XLlyRcuXL9e6deu0cOFCSdLUqVNVX18vSaqrq9OMGTMcRgUAOOGo0Pfu3auPP/5YP//5z1VWVqaysjKVl5drz549WrRokSzLUmlpabSzAgDCcHTIZePGjdq4ceNNj9fW1g46EADAGU4UBwBDUOgAYAgKHQAM4fi0RQCJJ9gbUlNbl6PZDI9bY1NTopwIQ4lCBwzSbYV09t1WR7Mlk3Mo9GGOQo/Qta6A2v3BWz4XcKcPuHfkt3pjEQsAKPRItfuDqrt45ZbPXb+KL/xVoJ/PGxeLWAAwMgt9MMcZ2cMGkKhGZKEP5jgje9gAEtWILHQANxvM/1yTPGlRTgMnKHQAkgb3P9f/y3JFOQ2c4MIiADAEhQ4AhqDQAcAQHEMHMGjuUSmOP1CVuO1AtFDoAAbN32v3e8Hd7eC2A9HBIRcAMASFDgCGoNABwBAUOgAYgkIHAENQ6ABgCAodAAxBoQOAISh0ADAEhQ4AhuDSfwDD2mC+uN20e8hQ6ACGtcF8cbtp95Ch0AHEHV/cHh0UOoC444vbo4MPRQHAEBQ6ABiCQgcAQ1DoAGCIqH4oGgqFtHnzZv373/9WSkqKtm3bprvvvjuaqwAA9COqhX706FEFAgH97ne/07lz57Rjxw794he/iOYqACBqBnO6pDtJCoacrTfJk+ZscABRLfS3335b999/vyRp+vTpunDhQjQXDwBRNdjTJc9+8JGj2f/LcjmaG4jLtu3+L6OK0LPPPqv58+drzpw5kqS5c+fq6NGjcrtv/b5x7tw5eTyeaK0eAEYEv9+v6dOn3/R4VPfQ09PT1dnZ2fdzKBTqt8wl3TIQAMCZqJ7lcu+996qurk7S9b3vyZMnR3PxAIAwonrI5cZZLhcvXpRt23ruued0zz33RGvxAIAwolroAID44cIiADAEhQ4AhqDQAcAQw+Z+6Il4W4Hz58/rRz/6kWpqatTY2KjKykq5XC5NmjRJ1dXVSkoa+vdLy7K0YcMGNTc3KxAIaOXKlZo4cWLcs/X29mrjxo16//33lZycrO3bt8u27bjnuuHq1at6+OGH9etf/1putzthcn3jG99QRkaGJCk3N1eLFi3SD3/4QyUnJ6u4uFhPPPFEXHLt27dPb775pizL0pIlS1RUVBT3bXbkyBH9/ve/l3T9PG2v16uampq4by/LslRZWanm5mYlJSVp69atsXuN2cPEX//6V7uiosK2bds+e/asvWLFirjm2b9/v/3Vr37VfuSRR2zbtu3HH3/cPn36tG3btl1VVWX/7W9/i0uuV155xd62bZtt27bd2tpqz5kzJyGyvfHGG3ZlZaVt27Z9+vRpe8WKFQmRy7ZtOxAI2N///vft+fPn25cuXUqYXD09PfbXv/71Tz32ta99zW5sbLRDoZD93e9+175w4cKQ5zp9+rT9+OOP2729vXZHR4f905/+NGG22Q2bN2+2X3rppYTYXm+88Ya9evVq27Zt+/jx4/YTTzwRs+01bA65JNptBfLy8rRnz56+nxsaGlRUVCRJKikp0cmTJ+OS64EHHtBTTz3V93NycnJCZPvyl7+srVu3SpIuX76snJychMglSTt37tTixYv1mc98RlLi/C7/9a9/qbu7W8uXL9eyZct05swZBQIB5eXlyeVyqbi4WKdOnRryXMePH9fkyZO1atUqrVixQnPnzk2YbSZJ//znP3Xp0iV95StfSYjtlZ+fr97eXoVCIXV0dMjtdsdsew2bQu/o6FB6enrfz8nJyQoGb/1N30OhtLT0U1fB2rYtl+v6/RnS0tLU3t4el1xpaWlKT09XR0eHVq9erfLy8oTJ5na7VVFRoa1bt6q0tDQhch05ckRZWVl9OwtS4vwuR48ere985zv61a9+pS1btmj9+vUaM2ZM3/PxytbW1qYLFy7ohRde0JYtW7R27dqE2WbS9cNBq1atuqkz4pUrNTVVzc3NWrBggaqqqlRWVhaz7TVsjqFHeluBofa/x786OzuVmZkZtyw+n0+rVq3S0qVL9dBDD2nXrl0Jk23nzp1au3atvv3tb8vv98c916uvviqXy6VTp07J6/WqoqJCra2f3KwpntsrPz9fd999t1wul/Lz85WRkaGPPvrkZlDxyjZu3DgVFBQoJSVFBQUF8ng8amlpiXsuSfr444/13nvvadasWero6PhUZ8Qr14EDB1RcXKynn35aPp9Pjz76qCzLikmuYbOHnui3FZg6darq6+slSXV1dZoxY0Zccly5ckXLly/XunXrtHDhwoTJ9oc//EH79u2TJI0ZM0Yul0vTpk2Le66DBw+qtrZWNTU1Kiws1M6dO1VSUhL3XJL0yiuvaMeOHZKkDz/8UN3d3UpNTdUHH3wg27Z1/PjxuGS777779NZbb8m27b5cs2fPTohtdubMGX3hC1+QdH0ncNSoUXHfXpmZmX0fbI8dO1bBYDBm/yaHzZWiiXhbgaamJv3gBz/Qyy+/rPfff19VVVWyLEsFBQXatm2bkpOThzzTtm3b9Je//EUFBQV9jz377LPatm1bXLN1dXVp/fr1unLlioLBoL73ve/pnnvuSYhtdkNZWZk2b96spKSkhMgVCAS0fv16Xb58WS6XS2vXrlVSUpKee+459fb2qri4WGvWrBnyXJL0/PPPq76+XrZta82aNcrNzU2Ibfbiiy/K7Xbrsccek3R95y/e26uzs1MbNmzQf//7X1mWpWXLlmnatGkx2V7DptABAOENm0MuAIDwKHQAMASFDgCGoNABwBAUOgAYgkLHiLZ//34VFxd/6iInYLii0DGi/fGPf9SDDz6oP//5z/GOAgxa4lw7Dwyx+vp65eXlafHixVq3bp0efvhhvfPOO9qyZYvS0tKUnZ0tj8ejHTt2qKamRn/605/kcrn04IMPatmyZfGOD9yEPXSMWIcPH9YjjzzSd1+S8+fPq7q6Wjt27NBvfvMb5eXlSZIuXbqk119/XYcOHdKhQ4d09OhRvffee3FOD9yMPXSMSNeuXVNdXZ1aW1tVU1Ojjo4O1dbW6j//+Y8mTZok6fo9S15//XVdvHhRly9f7ruc/Nq1a/rggw8+dXsFIBFQ6BiRXnvtNX3rW99SRUWFJKm7u1tf+tKXNHr0aF26dEkTJ07U+fPnJUkFBQWaOHGiXnzxRblcLh04cCDhbg4HSBQ6RqjDhw/r+eef7/t5zJgxmj9/vnJycrRhwwalpqZq1KhRuvPOOzVlyhTNnj1bS5YsUSAQ0Oc+9zndeeedcUwP3Bo35wL+x8GDB7VgwQJlZWXpxz/+sUaNGhW37+0EIsUeOvA/srOztXz5cqWmpiojI6PvfuTAcMAeOgAYgtMWAcAQFDoAGIJCBwBDUOgAYAgKHQAM8f/5SDYhll277QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train['Age'].dropna(),kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x957dc8f28>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.boxplot(x=\"Pclass\",y=\"Age\",data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_mean(cols):\n",
    "    Age=cols[0]\n",
    "    Pclass=cols[1]\n",
    "\n",
    "\n",
    "\n",
    "    if pd.isnull(Age):\n",
    "\n",
    "        if Pclass == 1:\n",
    "            return 37\n",
    "\n",
    "        elif Pclass == 2:\n",
    "            return 28\n",
    "\n",
    "        else:\n",
    "            return 25\n",
    "\n",
    "    else:\n",
    "        return Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age']=train[['Age','Pclass']].apply(col_mean,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22.0\n",
       "1    38.0\n",
       "2    26.0\n",
       "3    35.0\n",
       "4    35.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Age'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.206700336700333"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x959b50d30>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train['Age'].dropna(),kde=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=train.drop(['Survived',''], axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=train['Survived']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.8,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm       target\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris=pd.read_csv('E:\\\\python\\\\csv files\\\\Iris.csv')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'C:\\\\Users\\\\TEJ\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer=load_breast_cancer()\n",
    "cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.DESCR #description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\TEJ\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  radius error  texture error  perimeter error  \\\n",
       "0                 0.07871        1.0950         0.9053            8.589   \n",
       "1                 0.05667        0.5435         0.7339            3.398   \n",
       "2                 0.05999        0.7456         0.7869            4.585   \n",
       "3                 0.09744        0.4956         1.1560            3.445   \n",
       "4                 0.05883        0.7572         0.7813            5.438   \n",
       "\n",
       "   area error  smoothness error  compactness error  concavity error  \\\n",
       "0      153.40          0.006399            0.04904          0.05373   \n",
       "1       74.08          0.005225            0.01308          0.01860   \n",
       "2       94.03          0.006150            0.04006          0.03832   \n",
       "3       27.23          0.009110            0.07458          0.05661   \n",
       "4       94.44          0.011490            0.02461          0.05688   \n",
       "\n",
       "   concave points error  symmetry error  fractal dimension error  \\\n",
       "0               0.01587         0.03003                 0.006193   \n",
       "1               0.01340         0.01389                 0.003532   \n",
       "2               0.02058         0.02250                 0.004571   \n",
       "3               0.01867         0.05963                 0.009208   \n",
       "4               0.01885         0.01756                 0.005115   \n",
       "\n",
       "   worst radius  worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0         25.38          17.33           184.60      2019.0            0.1622   \n",
       "1         24.99          23.41           158.80      1956.0            0.1238   \n",
       "2         23.57          25.53           152.50      1709.0            0.1444   \n",
       "3         14.91          26.50            98.87       567.7            0.2098   \n",
       "4         22.54          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(cancer.data,columns=(cancer['feature_names']))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.09706398, -2.07333501,  1.26993369, ...,  2.29607613,\n",
       "         2.75062224,  1.93701461],\n",
       "       [ 1.82982061, -0.35363241,  1.68595471, ...,  1.0870843 ,\n",
       "        -0.24388967,  0.28118999],\n",
       "       [ 1.57988811,  0.45618695,  1.56650313, ...,  1.95500035,\n",
       "         1.152255  ,  0.20139121],\n",
       "       ...,\n",
       "       [ 0.70228425,  2.0455738 ,  0.67267578, ...,  0.41406869,\n",
       "        -1.10454895, -0.31840916],\n",
       "       [ 1.83834103,  2.33645719,  1.98252415, ...,  2.28998549,\n",
       "         1.91908301,  2.21963528],\n",
       "       [-1.80840125,  1.22179204, -1.81438851, ..., -1.74506282,\n",
       "        -0.04813821, -0.75120669]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=scaler.transform(df)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca=PCA(n_components=2)\n",
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.19283683,  1.94858307],\n",
       "       [ 2.3878018 , -3.76817174],\n",
       "       [ 5.73389628, -1.0751738 ],\n",
       "       ...,\n",
       "       [ 1.25617928, -1.90229671],\n",
       "       [10.37479406,  1.67201011],\n",
       "       [-5.4752433 , -0.67063679]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pca=pca.transform(data)\n",
    "x_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '2nd principal component')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x_pca[:,0],x_pca[:,1],c=cancer['target'],cmap=\"plasma\")\n",
    "plt.xlabel(\"1st principal component\")\n",
    "plt.ylabel(\"2nd principal component\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.19283683,  1.94858307],\n",
       "       [ 2.3878018 , -3.76817174],\n",
       "       [ 5.73389628, -1.0751738 ],\n",
       "       ...,\n",
       "       [ 1.25617928, -1.90229671],\n",
       "       [10.37479406,  1.67201011],\n",
       "       [-5.4752433 , -0.67063679]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW APPLY ANY MACHINE LEARNING ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.192837</td>\n",
       "      <td>1.948583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.387802</td>\n",
       "      <td>-3.768172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.733896</td>\n",
       "      <td>-1.075174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.122953</td>\n",
       "      <td>10.275589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.935302</td>\n",
       "      <td>-1.948072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a          b\n",
       "0  9.192837   1.948583\n",
       "1  2.387802  -3.768172\n",
       "2  5.733896  -1.075174\n",
       "3  7.122953  10.275589\n",
       "4  3.935302  -1.948072"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame(x_pca,columns=['a','b'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.DataFrame(cancer.target,columns=['target'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.192837</td>\n",
       "      <td>1.948583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.387802</td>\n",
       "      <td>-3.768172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.733896</td>\n",
       "      <td>-1.075174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.122953</td>\n",
       "      <td>10.275589</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.935302</td>\n",
       "      <td>-1.948072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.380247</td>\n",
       "      <td>3.949929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.238883</td>\n",
       "      <td>-2.690031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.143299</td>\n",
       "      <td>2.340244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.174924</td>\n",
       "      <td>3.391813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.351747</td>\n",
       "      <td>7.727174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.810414</td>\n",
       "      <td>-2.659275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.651100</td>\n",
       "      <td>0.066568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.185034</td>\n",
       "      <td>2.700976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.342126</td>\n",
       "      <td>-0.968279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.342379</td>\n",
       "      <td>4.861083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.075656</td>\n",
       "      <td>2.977061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.230055</td>\n",
       "      <td>-1.564758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.418011</td>\n",
       "      <td>1.418670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.948704</td>\n",
       "      <td>-4.114334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.237063</td>\n",
       "      <td>-0.188215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.578161</td>\n",
       "      <td>0.572808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-3.557336</td>\n",
       "      <td>1.662950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.733211</td>\n",
       "      <td>3.304964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.208524</td>\n",
       "      <td>-5.128367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.949632</td>\n",
       "      <td>-1.543752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.098563</td>\n",
       "      <td>2.018610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.510263</td>\n",
       "      <td>2.171625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.064054</td>\n",
       "      <td>-1.876552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.007264</td>\n",
       "      <td>0.537242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.715310</td>\n",
       "      <td>-1.523705</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>-1.142832</td>\n",
       "      <td>5.599458</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>-1.665475</td>\n",
       "      <td>2.389618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1.011712</td>\n",
       "      <td>1.092390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>-1.300930</td>\n",
       "      <td>-1.821415</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>-2.373429</td>\n",
       "      <td>-1.681576</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>-1.665871</td>\n",
       "      <td>-0.213963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>-1.927678</td>\n",
       "      <td>-1.137740</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>-4.237217</td>\n",
       "      <td>0.184272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>-2.677871</td>\n",
       "      <td>2.315793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>-3.836498</td>\n",
       "      <td>0.496250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>-2.551440</td>\n",
       "      <td>0.228330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>-4.694923</td>\n",
       "      <td>-0.767478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>-2.025037</td>\n",
       "      <td>1.261242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>-2.895948</td>\n",
       "      <td>-1.451636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>-3.502201</td>\n",
       "      <td>1.800832</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>-2.153904</td>\n",
       "      <td>-0.830069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>-2.055084</td>\n",
       "      <td>1.616459</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>-3.877290</td>\n",
       "      <td>1.084255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>-4.063862</td>\n",
       "      <td>0.122168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>-0.098667</td>\n",
       "      <td>-0.213560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>-1.089376</td>\n",
       "      <td>1.292848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>-0.481771</td>\n",
       "      <td>-0.178020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>-4.870310</td>\n",
       "      <td>-2.131106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>5.917613</td>\n",
       "      <td>3.482637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>8.741338</td>\n",
       "      <td>-0.573855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>6.439315</td>\n",
       "      <td>-3.576817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>3.793382</td>\n",
       "      <td>-3.584048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.256179</td>\n",
       "      <td>-1.902297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>10.374794</td>\n",
       "      <td>1.672010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-5.475243</td>\n",
       "      <td>-0.670637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             a          b  target\n",
       "0     9.192837   1.948583       0\n",
       "1     2.387802  -3.768172       0\n",
       "2     5.733896  -1.075174       0\n",
       "3     7.122953  10.275589       0\n",
       "4     3.935302  -1.948072       0\n",
       "5     2.380247   3.949929       0\n",
       "6     2.238883  -2.690031       0\n",
       "7     2.143299   2.340244       0\n",
       "8     3.174924   3.391813       0\n",
       "9     6.351747   7.727174       0\n",
       "10   -0.810414  -2.659275       0\n",
       "11    2.651100   0.066568       0\n",
       "12    8.185034   2.700976       0\n",
       "13    0.342126  -0.968279       0\n",
       "14    4.342379   4.861083       0\n",
       "15    4.075656   2.977061       0\n",
       "16    0.230055  -1.564758       0\n",
       "17    4.418011   1.418670       0\n",
       "18    4.948704  -4.114334       0\n",
       "19   -1.237063  -0.188215       1\n",
       "20   -1.578161   0.572808       1\n",
       "21   -3.557336   1.662950       1\n",
       "22    4.733211   3.304964       0\n",
       "23    4.208524  -5.128367       0\n",
       "24    4.949632  -1.543752       0\n",
       "25    7.098563   2.018610       0\n",
       "26    3.510263   2.171625       0\n",
       "27    3.064054  -1.876552       0\n",
       "28    4.007264   0.537242       0\n",
       "29    1.715310  -1.523705       0\n",
       "..         ...        ...     ...\n",
       "539  -1.142832   5.599458       1\n",
       "540  -1.665475   2.389618       1\n",
       "541   1.011712   1.092390       1\n",
       "542  -1.300930  -1.821415       1\n",
       "543  -2.373429  -1.681576       1\n",
       "544  -1.665871  -0.213963       1\n",
       "545  -1.927678  -1.137740       1\n",
       "546  -4.237217   0.184272       1\n",
       "547  -2.677871   2.315793       1\n",
       "548  -3.836498   0.496250       1\n",
       "549  -2.551440   0.228330       1\n",
       "550  -4.694923  -0.767478       1\n",
       "551  -2.025037   1.261242       1\n",
       "552  -2.895948  -1.451636       1\n",
       "553  -3.502201   1.800832       1\n",
       "554  -2.153904  -0.830069       1\n",
       "555  -2.055084   1.616459       1\n",
       "556  -3.877290   1.084255       1\n",
       "557  -4.063862   0.122168       1\n",
       "558  -0.098667  -0.213560       1\n",
       "559  -1.089376   1.292848       1\n",
       "560  -0.481771  -0.178020       1\n",
       "561  -4.870310  -2.131106       1\n",
       "562   5.917613   3.482637       0\n",
       "563   8.741338  -0.573855       0\n",
       "564   6.439315  -3.576817       0\n",
       "565   3.793382  -3.584048       0\n",
       "566   1.256179  -1.902297       0\n",
       "567  10.374794   1.672010       0\n",
       "568  -5.475243  -0.670637       1\n",
       "\n",
       "[569 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.concat([df1,df2],axis=1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.192837</td>\n",
       "      <td>1.948583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.387802</td>\n",
       "      <td>-3.768172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.733896</td>\n",
       "      <td>-1.075174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.122953</td>\n",
       "      <td>10.275589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.935302</td>\n",
       "      <td>-1.948072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.380247</td>\n",
       "      <td>3.949929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.238883</td>\n",
       "      <td>-2.690031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.143299</td>\n",
       "      <td>2.340244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.174924</td>\n",
       "      <td>3.391813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.351747</td>\n",
       "      <td>7.727174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.810414</td>\n",
       "      <td>-2.659275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.651100</td>\n",
       "      <td>0.066568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.185034</td>\n",
       "      <td>2.700976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.342126</td>\n",
       "      <td>-0.968279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.342379</td>\n",
       "      <td>4.861083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.075656</td>\n",
       "      <td>2.977061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.230055</td>\n",
       "      <td>-1.564758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.418011</td>\n",
       "      <td>1.418670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.948704</td>\n",
       "      <td>-4.114334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.237063</td>\n",
       "      <td>-0.188215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.578161</td>\n",
       "      <td>0.572808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-3.557336</td>\n",
       "      <td>1.662950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.733211</td>\n",
       "      <td>3.304964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.208524</td>\n",
       "      <td>-5.128367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.949632</td>\n",
       "      <td>-1.543752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.098563</td>\n",
       "      <td>2.018610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.510263</td>\n",
       "      <td>2.171625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.064054</td>\n",
       "      <td>-1.876552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.007264</td>\n",
       "      <td>0.537242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.715310</td>\n",
       "      <td>-1.523705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>-1.142832</td>\n",
       "      <td>5.599458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>-1.665475</td>\n",
       "      <td>2.389618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1.011712</td>\n",
       "      <td>1.092390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>-1.300930</td>\n",
       "      <td>-1.821415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>-2.373429</td>\n",
       "      <td>-1.681576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>-1.665871</td>\n",
       "      <td>-0.213963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>-1.927678</td>\n",
       "      <td>-1.137740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>-4.237217</td>\n",
       "      <td>0.184272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>-2.677871</td>\n",
       "      <td>2.315793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>-3.836498</td>\n",
       "      <td>0.496250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>-2.551440</td>\n",
       "      <td>0.228330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>-4.694923</td>\n",
       "      <td>-0.767478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>-2.025037</td>\n",
       "      <td>1.261242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>-2.895948</td>\n",
       "      <td>-1.451636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>-3.502201</td>\n",
       "      <td>1.800832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>-2.153904</td>\n",
       "      <td>-0.830069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>-2.055084</td>\n",
       "      <td>1.616459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>-3.877290</td>\n",
       "      <td>1.084255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>-4.063862</td>\n",
       "      <td>0.122168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>-0.098667</td>\n",
       "      <td>-0.213560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>-1.089376</td>\n",
       "      <td>1.292848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>-0.481771</td>\n",
       "      <td>-0.178020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>-4.870310</td>\n",
       "      <td>-2.131106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>5.917613</td>\n",
       "      <td>3.482637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>8.741338</td>\n",
       "      <td>-0.573855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>6.439315</td>\n",
       "      <td>-3.576817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>3.793382</td>\n",
       "      <td>-3.584048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.256179</td>\n",
       "      <td>-1.902297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>10.374794</td>\n",
       "      <td>1.672010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-5.475243</td>\n",
       "      <td>-0.670637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             a          b\n",
       "0     9.192837   1.948583\n",
       "1     2.387802  -3.768172\n",
       "2     5.733896  -1.075174\n",
       "3     7.122953  10.275589\n",
       "4     3.935302  -1.948072\n",
       "5     2.380247   3.949929\n",
       "6     2.238883  -2.690031\n",
       "7     2.143299   2.340244\n",
       "8     3.174924   3.391813\n",
       "9     6.351747   7.727174\n",
       "10   -0.810414  -2.659275\n",
       "11    2.651100   0.066568\n",
       "12    8.185034   2.700976\n",
       "13    0.342126  -0.968279\n",
       "14    4.342379   4.861083\n",
       "15    4.075656   2.977061\n",
       "16    0.230055  -1.564758\n",
       "17    4.418011   1.418670\n",
       "18    4.948704  -4.114334\n",
       "19   -1.237063  -0.188215\n",
       "20   -1.578161   0.572808\n",
       "21   -3.557336   1.662950\n",
       "22    4.733211   3.304964\n",
       "23    4.208524  -5.128367\n",
       "24    4.949632  -1.543752\n",
       "25    7.098563   2.018610\n",
       "26    3.510263   2.171625\n",
       "27    3.064054  -1.876552\n",
       "28    4.007264   0.537242\n",
       "29    1.715310  -1.523705\n",
       "..         ...        ...\n",
       "539  -1.142832   5.599458\n",
       "540  -1.665475   2.389618\n",
       "541   1.011712   1.092390\n",
       "542  -1.300930  -1.821415\n",
       "543  -2.373429  -1.681576\n",
       "544  -1.665871  -0.213963\n",
       "545  -1.927678  -1.137740\n",
       "546  -4.237217   0.184272\n",
       "547  -2.677871   2.315793\n",
       "548  -3.836498   0.496250\n",
       "549  -2.551440   0.228330\n",
       "550  -4.694923  -0.767478\n",
       "551  -2.025037   1.261242\n",
       "552  -2.895948  -1.451636\n",
       "553  -3.502201   1.800832\n",
       "554  -2.153904  -0.830069\n",
       "555  -2.055084   1.616459\n",
       "556  -3.877290   1.084255\n",
       "557  -4.063862   0.122168\n",
       "558  -0.098667  -0.213560\n",
       "559  -1.089376   1.292848\n",
       "560  -0.481771  -0.178020\n",
       "561  -4.870310  -2.131106\n",
       "562   5.917613   3.482637\n",
       "563   8.741338  -0.573855\n",
       "564   6.439315  -3.576817\n",
       "565   3.793382  -3.584048\n",
       "566   1.256179  -1.902297\n",
       "567  10.374794   1.672010\n",
       "568  -5.475243  -0.670637\n",
       "\n",
       "[569 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df3.drop('target',axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     0\n",
       "17     0\n",
       "18     0\n",
       "19     1\n",
       "20     1\n",
       "21     1\n",
       "22     0\n",
       "23     0\n",
       "24     0\n",
       "25     0\n",
       "26     0\n",
       "27     0\n",
       "28     0\n",
       "29     0\n",
       "      ..\n",
       "539    1\n",
       "540    1\n",
       "541    1\n",
       "542    1\n",
       "543    1\n",
       "544    1\n",
       "545    1\n",
       "546    1\n",
       "547    1\n",
       "548    1\n",
       "549    1\n",
       "550    1\n",
       "551    1\n",
       "552    1\n",
       "553    1\n",
       "554    1\n",
       "555    1\n",
       "556    1\n",
       "557    1\n",
       "558    1\n",
       "559    1\n",
       "560    1\n",
       "561    1\n",
       "562    0\n",
       "563    0\n",
       "564    0\n",
       "565    0\n",
       "566    0\n",
       "567    0\n",
       "568    1\n",
       "Name: target, Length: 569, dtype: int32"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df3['target']\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=KNeighborsClassifier()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88        63\n",
      "           1       0.93      0.93      0.93       108\n",
      "\n",
      "    accuracy                           0.91       171\n",
      "   macro avg       0.90      0.91      0.91       171\n",
      "weighted avg       0.91      0.91      0.91       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9122807017543859"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56   7]\n",
      " [  8 100]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECK ACCURACY WITHOUT PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'C:\\\\Users\\\\TEJ\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer=load_breast_cancer()\n",
    "cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  radius error  texture error  perimeter error  \\\n",
       "0                 0.07871        1.0950         0.9053            8.589   \n",
       "1                 0.05667        0.5435         0.7339            3.398   \n",
       "2                 0.05999        0.7456         0.7869            4.585   \n",
       "3                 0.09744        0.4956         1.1560            3.445   \n",
       "4                 0.05883        0.7572         0.7813            5.438   \n",
       "\n",
       "   area error  smoothness error  compactness error  concavity error  \\\n",
       "0      153.40          0.006399            0.04904          0.05373   \n",
       "1       74.08          0.005225            0.01308          0.01860   \n",
       "2       94.03          0.006150            0.04006          0.03832   \n",
       "3       27.23          0.009110            0.07458          0.05661   \n",
       "4       94.44          0.011490            0.02461          0.05688   \n",
       "\n",
       "   concave points error  symmetry error  fractal dimension error  \\\n",
       "0               0.01587         0.03003                 0.006193   \n",
       "1               0.01340         0.01389                 0.003532   \n",
       "2               0.02058         0.02250                 0.004571   \n",
       "3               0.01867         0.05963                 0.009208   \n",
       "4               0.01885         0.01756                 0.005115   \n",
       "\n",
       "   worst radius  worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0         25.38          17.33           184.60      2019.0            0.1622   \n",
       "1         24.99          23.41           158.80      1956.0            0.1238   \n",
       "2         23.57          25.53           152.50      1709.0            0.1444   \n",
       "3         14.91          26.50            98.87       567.7            0.2098   \n",
       "4         22.54          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4=pd.DataFrame(cancer.data,columns=(cancer['feature_names']))\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=pd.DataFrame(cancer.target,columns=['target'])\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  radius error  texture error  perimeter error  \\\n",
       "0                 0.07871        1.0950         0.9053            8.589   \n",
       "1                 0.05667        0.5435         0.7339            3.398   \n",
       "2                 0.05999        0.7456         0.7869            4.585   \n",
       "3                 0.09744        0.4956         1.1560            3.445   \n",
       "4                 0.05883        0.7572         0.7813            5.438   \n",
       "\n",
       "   area error  smoothness error  compactness error  concavity error  \\\n",
       "0      153.40          0.006399            0.04904          0.05373   \n",
       "1       74.08          0.005225            0.01308          0.01860   \n",
       "2       94.03          0.006150            0.04006          0.03832   \n",
       "3       27.23          0.009110            0.07458          0.05661   \n",
       "4       94.44          0.011490            0.02461          0.05688   \n",
       "\n",
       "   concave points error  symmetry error  fractal dimension error  \\\n",
       "0               0.01587         0.03003                 0.006193   \n",
       "1               0.01340         0.01389                 0.003532   \n",
       "2               0.02058         0.02250                 0.004571   \n",
       "3               0.01867         0.05963                 0.009208   \n",
       "4               0.01885         0.01756                 0.005115   \n",
       "\n",
       "   worst radius  worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0         25.38          17.33           184.60      2019.0            0.1622   \n",
       "1         24.99          23.41           158.80      1956.0            0.1238   \n",
       "2         23.57          25.53           152.50      1709.0            0.1444   \n",
       "3         14.91          26.50            98.87       567.7            0.2098   \n",
       "4         22.54          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  target  \n",
       "0                  0.11890       0  \n",
       "1                  0.08902       0  \n",
       "2                  0.08758       0  \n",
       "3                  0.17300       0  \n",
       "4                  0.07678       0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6=pd.concat([df4,df5],axis=1)\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.990</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.300100</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.5890</td>\n",
       "      <td>153.400</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.049040</td>\n",
       "      <td>0.053730</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.71190</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.570</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.070170</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.3980</td>\n",
       "      <td>74.080</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.690</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.5850</td>\n",
       "      <td>94.030</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.040060</td>\n",
       "      <td>0.038320</td>\n",
       "      <td>0.020580</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.420</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.4450</td>\n",
       "      <td>27.230</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.074580</td>\n",
       "      <td>0.056610</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.290</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.4380</td>\n",
       "      <td>94.440</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.024610</td>\n",
       "      <td>0.056880</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.450</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>2.2170</td>\n",
       "      <td>27.190</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>0.033450</td>\n",
       "      <td>0.036720</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>0.02165</td>\n",
       "      <td>0.005082</td>\n",
       "      <td>15.470</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.52490</td>\n",
       "      <td>0.53550</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.250</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.112700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>0.4467</td>\n",
       "      <td>0.7732</td>\n",
       "      <td>3.1800</td>\n",
       "      <td>53.910</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>0.013820</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>0.010390</td>\n",
       "      <td>0.01369</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>22.880</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.14420</td>\n",
       "      <td>0.25760</td>\n",
       "      <td>0.37840</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.710</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.093660</td>\n",
       "      <td>0.059850</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>0.5835</td>\n",
       "      <td>1.3770</td>\n",
       "      <td>3.8560</td>\n",
       "      <td>50.960</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>0.030290</td>\n",
       "      <td>0.024880</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.01486</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>17.060</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.16540</td>\n",
       "      <td>0.36820</td>\n",
       "      <td>0.26780</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.000</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.093530</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>1.0020</td>\n",
       "      <td>2.4060</td>\n",
       "      <td>24.320</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.035020</td>\n",
       "      <td>0.035530</td>\n",
       "      <td>0.012260</td>\n",
       "      <td>0.02143</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>15.490</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.17030</td>\n",
       "      <td>0.54010</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.460</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.085430</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>0.2976</td>\n",
       "      <td>1.5990</td>\n",
       "      <td>2.0390</td>\n",
       "      <td>23.940</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>0.072170</td>\n",
       "      <td>0.077430</td>\n",
       "      <td>0.014320</td>\n",
       "      <td>0.01789</td>\n",
       "      <td>0.010080</td>\n",
       "      <td>15.090</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.18530</td>\n",
       "      <td>1.05800</td>\n",
       "      <td>1.10500</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.020</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.032990</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>0.05697</td>\n",
       "      <td>0.3795</td>\n",
       "      <td>1.1870</td>\n",
       "      <td>2.4660</td>\n",
       "      <td>40.510</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.009269</td>\n",
       "      <td>0.011010</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.01460</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>19.190</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.11810</td>\n",
       "      <td>0.15510</td>\n",
       "      <td>0.14590</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.780</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.099540</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>0.06082</td>\n",
       "      <td>0.5058</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>3.5640</td>\n",
       "      <td>54.160</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.040610</td>\n",
       "      <td>0.027910</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>0.02008</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>20.420</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.13960</td>\n",
       "      <td>0.56090</td>\n",
       "      <td>0.39650</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19.170</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07800</td>\n",
       "      <td>0.9555</td>\n",
       "      <td>3.5680</td>\n",
       "      <td>11.0700</td>\n",
       "      <td>116.200</td>\n",
       "      <td>0.003139</td>\n",
       "      <td>0.082970</td>\n",
       "      <td>0.088900</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.04484</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>20.960</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.10370</td>\n",
       "      <td>0.39030</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.850</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.099380</td>\n",
       "      <td>0.053640</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>0.05338</td>\n",
       "      <td>0.4033</td>\n",
       "      <td>1.0780</td>\n",
       "      <td>2.9030</td>\n",
       "      <td>36.580</td>\n",
       "      <td>0.009769</td>\n",
       "      <td>0.031260</td>\n",
       "      <td>0.050510</td>\n",
       "      <td>0.019920</td>\n",
       "      <td>0.02981</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>16.840</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.19240</td>\n",
       "      <td>0.23220</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.730</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.080250</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.07682</td>\n",
       "      <td>0.2121</td>\n",
       "      <td>1.1690</td>\n",
       "      <td>2.0610</td>\n",
       "      <td>19.210</td>\n",
       "      <td>0.006429</td>\n",
       "      <td>0.059360</td>\n",
       "      <td>0.055010</td>\n",
       "      <td>0.016280</td>\n",
       "      <td>0.01961</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>15.030</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.16510</td>\n",
       "      <td>0.77250</td>\n",
       "      <td>0.69430</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.540</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.073640</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>0.07077</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>1.0330</td>\n",
       "      <td>2.8790</td>\n",
       "      <td>32.550</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.047410</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.01857</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>17.460</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.65770</td>\n",
       "      <td>0.70260</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.680</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.05922</td>\n",
       "      <td>0.4727</td>\n",
       "      <td>1.2400</td>\n",
       "      <td>3.1950</td>\n",
       "      <td>45.400</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>0.019980</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>0.01410</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>19.070</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.14640</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>0.29140</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.130</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.07356</td>\n",
       "      <td>0.5692</td>\n",
       "      <td>1.0730</td>\n",
       "      <td>3.8540</td>\n",
       "      <td>54.180</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.025010</td>\n",
       "      <td>0.031880</td>\n",
       "      <td>0.012970</td>\n",
       "      <td>0.01689</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>20.960</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.17890</td>\n",
       "      <td>0.42330</td>\n",
       "      <td>0.47840</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.810</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.05395</td>\n",
       "      <td>0.7582</td>\n",
       "      <td>1.0170</td>\n",
       "      <td>5.8650</td>\n",
       "      <td>112.400</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.018930</td>\n",
       "      <td>0.033910</td>\n",
       "      <td>0.015210</td>\n",
       "      <td>0.01356</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>27.320</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.15120</td>\n",
       "      <td>0.31500</td>\n",
       "      <td>0.53720</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.066640</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.05766</td>\n",
       "      <td>0.2699</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>2.0580</td>\n",
       "      <td>23.560</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.023870</td>\n",
       "      <td>0.013150</td>\n",
       "      <td>0.01980</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>15.110</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.045680</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.06811</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>0.7477</td>\n",
       "      <td>1.3830</td>\n",
       "      <td>14.670</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.018980</td>\n",
       "      <td>0.016980</td>\n",
       "      <td>0.006490</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>14.500</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.2773</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>1.9090</td>\n",
       "      <td>15.700</td>\n",
       "      <td>0.009606</td>\n",
       "      <td>0.014320</td>\n",
       "      <td>0.019850</td>\n",
       "      <td>0.014210</td>\n",
       "      <td>0.02027</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>10.230</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.340</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.097560</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.07032</td>\n",
       "      <td>0.4388</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>3.3840</td>\n",
       "      <td>44.910</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>0.053280</td>\n",
       "      <td>0.064460</td>\n",
       "      <td>0.022520</td>\n",
       "      <td>0.03672</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>18.070</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.13900</td>\n",
       "      <td>0.59540</td>\n",
       "      <td>0.63050</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21.160</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.09428</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.109700</td>\n",
       "      <td>0.086320</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.05278</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>1.1270</td>\n",
       "      <td>4.3030</td>\n",
       "      <td>93.990</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.012590</td>\n",
       "      <td>0.017150</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>0.01083</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>29.170</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.14010</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.31550</td>\n",
       "      <td>0.20090</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.07526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.650</td>\n",
       "      <td>21.38</td>\n",
       "      <td>110.00</td>\n",
       "      <td>904.6</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.14570</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.06330</td>\n",
       "      <td>0.8068</td>\n",
       "      <td>0.9017</td>\n",
       "      <td>5.4550</td>\n",
       "      <td>102.600</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>0.018820</td>\n",
       "      <td>0.027410</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.01468</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>26.460</td>\n",
       "      <td>31.56</td>\n",
       "      <td>177.00</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>0.18050</td>\n",
       "      <td>0.35780</td>\n",
       "      <td>0.46950</td>\n",
       "      <td>0.20950</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.09564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17.140</td>\n",
       "      <td>16.40</td>\n",
       "      <td>116.00</td>\n",
       "      <td>912.7</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.22760</td>\n",
       "      <td>0.222900</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>0.3040</td>\n",
       "      <td>0.07413</td>\n",
       "      <td>1.0460</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>7.2760</td>\n",
       "      <td>111.400</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>0.037990</td>\n",
       "      <td>0.037320</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>0.02308</td>\n",
       "      <td>0.007444</td>\n",
       "      <td>22.250</td>\n",
       "      <td>21.40</td>\n",
       "      <td>152.40</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.15450</td>\n",
       "      <td>0.39490</td>\n",
       "      <td>0.38530</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.4066</td>\n",
       "      <td>0.10590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14.580</td>\n",
       "      <td>21.53</td>\n",
       "      <td>97.41</td>\n",
       "      <td>644.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.18680</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.087830</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.06924</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>2.1100</td>\n",
       "      <td>21.050</td>\n",
       "      <td>0.004452</td>\n",
       "      <td>0.030550</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>0.013520</td>\n",
       "      <td>0.01454</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>17.620</td>\n",
       "      <td>33.21</td>\n",
       "      <td>122.40</td>\n",
       "      <td>896.9</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.66430</td>\n",
       "      <td>0.55390</td>\n",
       "      <td>0.27010</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.12750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18.610</td>\n",
       "      <td>20.25</td>\n",
       "      <td>122.10</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>0.09440</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.077310</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>0.05699</td>\n",
       "      <td>0.8529</td>\n",
       "      <td>1.8490</td>\n",
       "      <td>5.6320</td>\n",
       "      <td>93.540</td>\n",
       "      <td>0.010750</td>\n",
       "      <td>0.027220</td>\n",
       "      <td>0.050810</td>\n",
       "      <td>0.019110</td>\n",
       "      <td>0.02293</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>21.310</td>\n",
       "      <td>27.26</td>\n",
       "      <td>139.90</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>0.13380</td>\n",
       "      <td>0.21170</td>\n",
       "      <td>0.34460</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.07421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15.300</td>\n",
       "      <td>25.27</td>\n",
       "      <td>102.40</td>\n",
       "      <td>732.4</td>\n",
       "      <td>0.10820</td>\n",
       "      <td>0.16970</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.087510</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.06540</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>1.0120</td>\n",
       "      <td>3.4980</td>\n",
       "      <td>43.500</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.030570</td>\n",
       "      <td>0.035760</td>\n",
       "      <td>0.010830</td>\n",
       "      <td>0.01768</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>20.270</td>\n",
       "      <td>36.71</td>\n",
       "      <td>149.30</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>0.16410</td>\n",
       "      <td>0.61100</td>\n",
       "      <td>0.63350</td>\n",
       "      <td>0.20240</td>\n",
       "      <td>0.4027</td>\n",
       "      <td>0.09876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17.570</td>\n",
       "      <td>15.05</td>\n",
       "      <td>115.00</td>\n",
       "      <td>955.1</td>\n",
       "      <td>0.09847</td>\n",
       "      <td>0.11570</td>\n",
       "      <td>0.098750</td>\n",
       "      <td>0.079530</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.06149</td>\n",
       "      <td>0.6003</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>4.6550</td>\n",
       "      <td>61.100</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>0.030330</td>\n",
       "      <td>0.034070</td>\n",
       "      <td>0.013540</td>\n",
       "      <td>0.01925</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>20.010</td>\n",
       "      <td>19.52</td>\n",
       "      <td>134.90</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.28120</td>\n",
       "      <td>0.24890</td>\n",
       "      <td>0.14560</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.07919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>7.691</td>\n",
       "      <td>25.44</td>\n",
       "      <td>48.34</td>\n",
       "      <td>170.4</td>\n",
       "      <td>0.08668</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.092520</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.2037</td>\n",
       "      <td>0.07751</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>1.4790</td>\n",
       "      <td>1.4450</td>\n",
       "      <td>11.730</td>\n",
       "      <td>0.015470</td>\n",
       "      <td>0.064570</td>\n",
       "      <td>0.092520</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.02105</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>8.678</td>\n",
       "      <td>31.89</td>\n",
       "      <td>54.49</td>\n",
       "      <td>223.6</td>\n",
       "      <td>0.15960</td>\n",
       "      <td>0.30640</td>\n",
       "      <td>0.33930</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.10660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>11.540</td>\n",
       "      <td>14.44</td>\n",
       "      <td>74.65</td>\n",
       "      <td>402.9</td>\n",
       "      <td>0.09984</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.067370</td>\n",
       "      <td>0.025940</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.06782</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>1.7680</td>\n",
       "      <td>1.6280</td>\n",
       "      <td>20.860</td>\n",
       "      <td>0.012150</td>\n",
       "      <td>0.041120</td>\n",
       "      <td>0.055530</td>\n",
       "      <td>0.014940</td>\n",
       "      <td>0.01840</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>12.260</td>\n",
       "      <td>19.68</td>\n",
       "      <td>78.78</td>\n",
       "      <td>457.8</td>\n",
       "      <td>0.13450</td>\n",
       "      <td>0.21180</td>\n",
       "      <td>0.17970</td>\n",
       "      <td>0.06918</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>0.08134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>14.470</td>\n",
       "      <td>24.99</td>\n",
       "      <td>95.81</td>\n",
       "      <td>656.4</td>\n",
       "      <td>0.08837</td>\n",
       "      <td>0.12300</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>0.06341</td>\n",
       "      <td>0.2542</td>\n",
       "      <td>1.0790</td>\n",
       "      <td>2.6150</td>\n",
       "      <td>23.110</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.046530</td>\n",
       "      <td>0.038290</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>0.02068</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>16.220</td>\n",
       "      <td>31.73</td>\n",
       "      <td>113.50</td>\n",
       "      <td>808.9</td>\n",
       "      <td>0.13400</td>\n",
       "      <td>0.42020</td>\n",
       "      <td>0.40400</td>\n",
       "      <td>0.12050</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>14.740</td>\n",
       "      <td>25.42</td>\n",
       "      <td>94.70</td>\n",
       "      <td>668.6</td>\n",
       "      <td>0.08275</td>\n",
       "      <td>0.07214</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>0.030270</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.05680</td>\n",
       "      <td>0.3031</td>\n",
       "      <td>1.3850</td>\n",
       "      <td>2.1770</td>\n",
       "      <td>27.410</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>0.01870</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>16.510</td>\n",
       "      <td>32.29</td>\n",
       "      <td>107.40</td>\n",
       "      <td>826.4</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>0.13760</td>\n",
       "      <td>0.16110</td>\n",
       "      <td>0.10950</td>\n",
       "      <td>0.2722</td>\n",
       "      <td>0.06956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>13.210</td>\n",
       "      <td>28.06</td>\n",
       "      <td>84.88</td>\n",
       "      <td>538.4</td>\n",
       "      <td>0.08671</td>\n",
       "      <td>0.06877</td>\n",
       "      <td>0.029870</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.05781</td>\n",
       "      <td>0.2351</td>\n",
       "      <td>1.5970</td>\n",
       "      <td>1.5390</td>\n",
       "      <td>17.850</td>\n",
       "      <td>0.004973</td>\n",
       "      <td>0.013720</td>\n",
       "      <td>0.014980</td>\n",
       "      <td>0.009117</td>\n",
       "      <td>0.01724</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>14.370</td>\n",
       "      <td>37.17</td>\n",
       "      <td>92.48</td>\n",
       "      <td>629.6</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.13810</td>\n",
       "      <td>0.10620</td>\n",
       "      <td>0.07958</td>\n",
       "      <td>0.2473</td>\n",
       "      <td>0.06443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>13.870</td>\n",
       "      <td>20.70</td>\n",
       "      <td>89.77</td>\n",
       "      <td>584.8</td>\n",
       "      <td>0.09578</td>\n",
       "      <td>0.10180</td>\n",
       "      <td>0.036880</td>\n",
       "      <td>0.023690</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.06688</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>1.0470</td>\n",
       "      <td>2.0760</td>\n",
       "      <td>23.120</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.021720</td>\n",
       "      <td>0.026150</td>\n",
       "      <td>0.009061</td>\n",
       "      <td>0.01490</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>15.050</td>\n",
       "      <td>24.75</td>\n",
       "      <td>99.17</td>\n",
       "      <td>688.6</td>\n",
       "      <td>0.12640</td>\n",
       "      <td>0.20370</td>\n",
       "      <td>0.13770</td>\n",
       "      <td>0.06845</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.08492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>13.620</td>\n",
       "      <td>23.23</td>\n",
       "      <td>87.19</td>\n",
       "      <td>573.2</td>\n",
       "      <td>0.09246</td>\n",
       "      <td>0.06747</td>\n",
       "      <td>0.029740</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>0.1664</td>\n",
       "      <td>0.05801</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>1.3360</td>\n",
       "      <td>2.0660</td>\n",
       "      <td>31.240</td>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.020990</td>\n",
       "      <td>0.020210</td>\n",
       "      <td>0.009064</td>\n",
       "      <td>0.02087</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>15.350</td>\n",
       "      <td>29.09</td>\n",
       "      <td>97.58</td>\n",
       "      <td>729.8</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.15170</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>0.07174</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.06953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>10.320</td>\n",
       "      <td>16.35</td>\n",
       "      <td>65.31</td>\n",
       "      <td>324.9</td>\n",
       "      <td>0.09434</td>\n",
       "      <td>0.04994</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.06201</td>\n",
       "      <td>0.2104</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>1.3560</td>\n",
       "      <td>12.970</td>\n",
       "      <td>0.007086</td>\n",
       "      <td>0.007247</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.01560</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>11.250</td>\n",
       "      <td>21.77</td>\n",
       "      <td>71.12</td>\n",
       "      <td>384.9</td>\n",
       "      <td>0.12850</td>\n",
       "      <td>0.08842</td>\n",
       "      <td>0.04384</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.07399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>10.260</td>\n",
       "      <td>16.58</td>\n",
       "      <td>65.85</td>\n",
       "      <td>320.8</td>\n",
       "      <td>0.08877</td>\n",
       "      <td>0.08066</td>\n",
       "      <td>0.043580</td>\n",
       "      <td>0.024380</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>0.06714</td>\n",
       "      <td>0.1144</td>\n",
       "      <td>1.0230</td>\n",
       "      <td>0.9887</td>\n",
       "      <td>7.326</td>\n",
       "      <td>0.010270</td>\n",
       "      <td>0.030840</td>\n",
       "      <td>0.026130</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.02277</td>\n",
       "      <td>0.005890</td>\n",
       "      <td>10.830</td>\n",
       "      <td>22.04</td>\n",
       "      <td>71.08</td>\n",
       "      <td>357.4</td>\n",
       "      <td>0.14610</td>\n",
       "      <td>0.22460</td>\n",
       "      <td>0.17830</td>\n",
       "      <td>0.08333</td>\n",
       "      <td>0.2691</td>\n",
       "      <td>0.09479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>9.683</td>\n",
       "      <td>19.34</td>\n",
       "      <td>61.05</td>\n",
       "      <td>285.7</td>\n",
       "      <td>0.08491</td>\n",
       "      <td>0.05030</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.06235</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>1.3630</td>\n",
       "      <td>2.0540</td>\n",
       "      <td>18.240</td>\n",
       "      <td>0.007440</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.02203</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>10.930</td>\n",
       "      <td>25.59</td>\n",
       "      <td>69.10</td>\n",
       "      <td>364.2</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.09546</td>\n",
       "      <td>0.09350</td>\n",
       "      <td>0.03846</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.07920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>10.820</td>\n",
       "      <td>24.21</td>\n",
       "      <td>68.89</td>\n",
       "      <td>361.6</td>\n",
       "      <td>0.08192</td>\n",
       "      <td>0.06602</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.06328</td>\n",
       "      <td>0.5196</td>\n",
       "      <td>1.9180</td>\n",
       "      <td>3.5640</td>\n",
       "      <td>33.000</td>\n",
       "      <td>0.008263</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.012770</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.02466</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>13.030</td>\n",
       "      <td>31.45</td>\n",
       "      <td>83.90</td>\n",
       "      <td>505.6</td>\n",
       "      <td>0.12040</td>\n",
       "      <td>0.16330</td>\n",
       "      <td>0.06194</td>\n",
       "      <td>0.03264</td>\n",
       "      <td>0.3059</td>\n",
       "      <td>0.07626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>10.860</td>\n",
       "      <td>21.48</td>\n",
       "      <td>68.51</td>\n",
       "      <td>360.5</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.04227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1661</td>\n",
       "      <td>0.05948</td>\n",
       "      <td>0.3163</td>\n",
       "      <td>1.3040</td>\n",
       "      <td>2.1150</td>\n",
       "      <td>20.670</td>\n",
       "      <td>0.009579</td>\n",
       "      <td>0.011040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03004</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>11.660</td>\n",
       "      <td>24.77</td>\n",
       "      <td>74.08</td>\n",
       "      <td>412.3</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.07348</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.06592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>11.130</td>\n",
       "      <td>22.44</td>\n",
       "      <td>71.49</td>\n",
       "      <td>378.4</td>\n",
       "      <td>0.09566</td>\n",
       "      <td>0.08194</td>\n",
       "      <td>0.048240</td>\n",
       "      <td>0.022570</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.06552</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>1.4670</td>\n",
       "      <td>1.9940</td>\n",
       "      <td>17.850</td>\n",
       "      <td>0.003495</td>\n",
       "      <td>0.030510</td>\n",
       "      <td>0.034450</td>\n",
       "      <td>0.010240</td>\n",
       "      <td>0.02912</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>12.020</td>\n",
       "      <td>28.26</td>\n",
       "      <td>77.80</td>\n",
       "      <td>436.6</td>\n",
       "      <td>0.10870</td>\n",
       "      <td>0.17820</td>\n",
       "      <td>0.15640</td>\n",
       "      <td>0.06413</td>\n",
       "      <td>0.3169</td>\n",
       "      <td>0.08032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>12.770</td>\n",
       "      <td>29.43</td>\n",
       "      <td>81.35</td>\n",
       "      <td>507.9</td>\n",
       "      <td>0.08276</td>\n",
       "      <td>0.04234</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.014990</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.05637</td>\n",
       "      <td>0.2409</td>\n",
       "      <td>1.3670</td>\n",
       "      <td>1.4770</td>\n",
       "      <td>18.760</td>\n",
       "      <td>0.008835</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>0.013280</td>\n",
       "      <td>0.009305</td>\n",
       "      <td>0.01897</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>13.870</td>\n",
       "      <td>36.00</td>\n",
       "      <td>88.10</td>\n",
       "      <td>594.7</td>\n",
       "      <td>0.12340</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.08653</td>\n",
       "      <td>0.06498</td>\n",
       "      <td>0.2407</td>\n",
       "      <td>0.06484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>9.333</td>\n",
       "      <td>21.94</td>\n",
       "      <td>59.01</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.09240</td>\n",
       "      <td>0.05605</td>\n",
       "      <td>0.039960</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>0.1692</td>\n",
       "      <td>0.06576</td>\n",
       "      <td>0.3013</td>\n",
       "      <td>1.8790</td>\n",
       "      <td>2.1210</td>\n",
       "      <td>17.860</td>\n",
       "      <td>0.010940</td>\n",
       "      <td>0.018340</td>\n",
       "      <td>0.039960</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>0.03759</td>\n",
       "      <td>0.004623</td>\n",
       "      <td>9.845</td>\n",
       "      <td>25.05</td>\n",
       "      <td>62.86</td>\n",
       "      <td>295.8</td>\n",
       "      <td>0.11030</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.07993</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.2435</td>\n",
       "      <td>0.07393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>12.880</td>\n",
       "      <td>28.92</td>\n",
       "      <td>82.50</td>\n",
       "      <td>514.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.05824</td>\n",
       "      <td>0.061950</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.05708</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>1.3600</td>\n",
       "      <td>1.5020</td>\n",
       "      <td>16.830</td>\n",
       "      <td>0.008412</td>\n",
       "      <td>0.021530</td>\n",
       "      <td>0.038980</td>\n",
       "      <td>0.007620</td>\n",
       "      <td>0.01695</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>13.890</td>\n",
       "      <td>35.74</td>\n",
       "      <td>88.84</td>\n",
       "      <td>595.7</td>\n",
       "      <td>0.12270</td>\n",
       "      <td>0.16200</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.06493</td>\n",
       "      <td>0.2372</td>\n",
       "      <td>0.07242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>10.290</td>\n",
       "      <td>27.61</td>\n",
       "      <td>65.67</td>\n",
       "      <td>321.4</td>\n",
       "      <td>0.09030</td>\n",
       "      <td>0.07658</td>\n",
       "      <td>0.059990</td>\n",
       "      <td>0.027380</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.06127</td>\n",
       "      <td>0.2199</td>\n",
       "      <td>2.2390</td>\n",
       "      <td>1.4370</td>\n",
       "      <td>14.460</td>\n",
       "      <td>0.012050</td>\n",
       "      <td>0.027360</td>\n",
       "      <td>0.048040</td>\n",
       "      <td>0.017210</td>\n",
       "      <td>0.01843</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>10.840</td>\n",
       "      <td>34.91</td>\n",
       "      <td>69.57</td>\n",
       "      <td>357.6</td>\n",
       "      <td>0.13840</td>\n",
       "      <td>0.17100</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.09127</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.08283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>10.160</td>\n",
       "      <td>19.59</td>\n",
       "      <td>64.73</td>\n",
       "      <td>311.7</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.07504</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.06331</td>\n",
       "      <td>0.2441</td>\n",
       "      <td>2.0900</td>\n",
       "      <td>1.6480</td>\n",
       "      <td>16.800</td>\n",
       "      <td>0.012910</td>\n",
       "      <td>0.022220</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.02572</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>10.650</td>\n",
       "      <td>22.88</td>\n",
       "      <td>67.88</td>\n",
       "      <td>347.3</td>\n",
       "      <td>0.12650</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>0.01005</td>\n",
       "      <td>0.02232</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.06742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>9.423</td>\n",
       "      <td>27.88</td>\n",
       "      <td>59.26</td>\n",
       "      <td>271.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.04971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1742</td>\n",
       "      <td>0.06059</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>2.9270</td>\n",
       "      <td>3.6180</td>\n",
       "      <td>29.110</td>\n",
       "      <td>0.011590</td>\n",
       "      <td>0.011240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03004</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>10.490</td>\n",
       "      <td>34.24</td>\n",
       "      <td>66.50</td>\n",
       "      <td>330.6</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.07158</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.06969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>14.590</td>\n",
       "      <td>22.68</td>\n",
       "      <td>96.39</td>\n",
       "      <td>657.1</td>\n",
       "      <td>0.08473</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.037360</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>0.06147</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>1.1080</td>\n",
       "      <td>2.2240</td>\n",
       "      <td>19.540</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.046390</td>\n",
       "      <td>0.065780</td>\n",
       "      <td>0.016060</td>\n",
       "      <td>0.01638</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>15.480</td>\n",
       "      <td>27.27</td>\n",
       "      <td>105.90</td>\n",
       "      <td>733.5</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>0.31710</td>\n",
       "      <td>0.36620</td>\n",
       "      <td>0.11050</td>\n",
       "      <td>0.2258</td>\n",
       "      <td>0.08004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>11.510</td>\n",
       "      <td>23.93</td>\n",
       "      <td>74.52</td>\n",
       "      <td>403.5</td>\n",
       "      <td>0.09261</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.06570</td>\n",
       "      <td>0.2388</td>\n",
       "      <td>2.9040</td>\n",
       "      <td>1.9360</td>\n",
       "      <td>16.970</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.029820</td>\n",
       "      <td>0.057380</td>\n",
       "      <td>0.012670</td>\n",
       "      <td>0.01488</td>\n",
       "      <td>0.004738</td>\n",
       "      <td>12.480</td>\n",
       "      <td>37.16</td>\n",
       "      <td>82.28</td>\n",
       "      <td>474.2</td>\n",
       "      <td>0.12980</td>\n",
       "      <td>0.25170</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.09653</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.08732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>14.050</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.09929</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.044620</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>0.1537</td>\n",
       "      <td>0.06171</td>\n",
       "      <td>0.3645</td>\n",
       "      <td>1.4920</td>\n",
       "      <td>2.8880</td>\n",
       "      <td>29.840</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.026780</td>\n",
       "      <td>0.020710</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.02080</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>15.300</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.20</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.12410</td>\n",
       "      <td>0.22640</td>\n",
       "      <td>0.13260</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.08321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>11.200</td>\n",
       "      <td>29.37</td>\n",
       "      <td>70.67</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.07449</td>\n",
       "      <td>0.03558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.05502</td>\n",
       "      <td>0.3141</td>\n",
       "      <td>3.8960</td>\n",
       "      <td>2.0410</td>\n",
       "      <td>22.810</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01989</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>11.920</td>\n",
       "      <td>38.30</td>\n",
       "      <td>75.19</td>\n",
       "      <td>439.6</td>\n",
       "      <td>0.09267</td>\n",
       "      <td>0.05494</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.05905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>15.220</td>\n",
       "      <td>30.62</td>\n",
       "      <td>103.40</td>\n",
       "      <td>716.9</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.094290</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.07152</td>\n",
       "      <td>0.2602</td>\n",
       "      <td>1.2050</td>\n",
       "      <td>2.3620</td>\n",
       "      <td>22.650</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.048440</td>\n",
       "      <td>0.073590</td>\n",
       "      <td>0.016080</td>\n",
       "      <td>0.02137</td>\n",
       "      <td>0.006142</td>\n",
       "      <td>17.520</td>\n",
       "      <td>42.79</td>\n",
       "      <td>128.70</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0.14170</td>\n",
       "      <td>0.79170</td>\n",
       "      <td>1.17000</td>\n",
       "      <td>0.23560</td>\n",
       "      <td>0.4089</td>\n",
       "      <td>0.14090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>20.920</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.317400</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.06879</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>1.0260</td>\n",
       "      <td>8.7580</td>\n",
       "      <td>118.800</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.078450</td>\n",
       "      <td>0.026240</td>\n",
       "      <td>0.02057</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>24.290</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.10</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.14070</td>\n",
       "      <td>0.41860</td>\n",
       "      <td>0.65990</td>\n",
       "      <td>0.25420</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.560</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.243900</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.6730</td>\n",
       "      <td>158.700</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.028910</td>\n",
       "      <td>0.051980</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.2030</td>\n",
       "      <td>99.040</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.024230</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.016780</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.600</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.092510</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.4250</td>\n",
       "      <td>48.550</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.037310</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.015570</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.34030</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.600</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.351400</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.7720</td>\n",
       "      <td>86.220</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.061580</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.016640</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.760</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.5480</td>\n",
       "      <td>19.150</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.004660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0         17.990         10.38          122.80     1001.0          0.11840   \n",
       "1         20.570         17.77          132.90     1326.0          0.08474   \n",
       "2         19.690         21.25          130.00     1203.0          0.10960   \n",
       "3         11.420         20.38           77.58      386.1          0.14250   \n",
       "4         20.290         14.34          135.10     1297.0          0.10030   \n",
       "5         12.450         15.70           82.57      477.1          0.12780   \n",
       "6         18.250         19.98          119.60     1040.0          0.09463   \n",
       "7         13.710         20.83           90.20      577.9          0.11890   \n",
       "8         13.000         21.82           87.50      519.8          0.12730   \n",
       "9         12.460         24.04           83.97      475.9          0.11860   \n",
       "10        16.020         23.24          102.70      797.8          0.08206   \n",
       "11        15.780         17.89          103.60      781.0          0.09710   \n",
       "12        19.170         24.80          132.40     1123.0          0.09740   \n",
       "13        15.850         23.95          103.70      782.7          0.08401   \n",
       "14        13.730         22.61           93.60      578.3          0.11310   \n",
       "15        14.540         27.54           96.73      658.8          0.11390   \n",
       "16        14.680         20.13           94.74      684.5          0.09867   \n",
       "17        16.130         20.68          108.10      798.8          0.11700   \n",
       "18        19.810         22.15          130.00     1260.0          0.09831   \n",
       "19        13.540         14.36           87.46      566.3          0.09779   \n",
       "20        13.080         15.71           85.63      520.0          0.10750   \n",
       "21         9.504         12.44           60.34      273.9          0.10240   \n",
       "22        15.340         14.26          102.50      704.4          0.10730   \n",
       "23        21.160         23.04          137.20     1404.0          0.09428   \n",
       "24        16.650         21.38          110.00      904.6          0.11210   \n",
       "25        17.140         16.40          116.00      912.7          0.11860   \n",
       "26        14.580         21.53           97.41      644.8          0.10540   \n",
       "27        18.610         20.25          122.10     1094.0          0.09440   \n",
       "28        15.300         25.27          102.40      732.4          0.10820   \n",
       "29        17.570         15.05          115.00      955.1          0.09847   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "539        7.691         25.44           48.34      170.4          0.08668   \n",
       "540       11.540         14.44           74.65      402.9          0.09984   \n",
       "541       14.470         24.99           95.81      656.4          0.08837   \n",
       "542       14.740         25.42           94.70      668.6          0.08275   \n",
       "543       13.210         28.06           84.88      538.4          0.08671   \n",
       "544       13.870         20.70           89.77      584.8          0.09578   \n",
       "545       13.620         23.23           87.19      573.2          0.09246   \n",
       "546       10.320         16.35           65.31      324.9          0.09434   \n",
       "547       10.260         16.58           65.85      320.8          0.08877   \n",
       "548        9.683         19.34           61.05      285.7          0.08491   \n",
       "549       10.820         24.21           68.89      361.6          0.08192   \n",
       "550       10.860         21.48           68.51      360.5          0.07431   \n",
       "551       11.130         22.44           71.49      378.4          0.09566   \n",
       "552       12.770         29.43           81.35      507.9          0.08276   \n",
       "553        9.333         21.94           59.01      264.0          0.09240   \n",
       "554       12.880         28.92           82.50      514.3          0.08123   \n",
       "555       10.290         27.61           65.67      321.4          0.09030   \n",
       "556       10.160         19.59           64.73      311.7          0.10030   \n",
       "557        9.423         27.88           59.26      271.3          0.08123   \n",
       "558       14.590         22.68           96.39      657.1          0.08473   \n",
       "559       11.510         23.93           74.52      403.5          0.09261   \n",
       "560       14.050         27.15           91.38      600.4          0.09929   \n",
       "561       11.200         29.37           70.67      386.0          0.07449   \n",
       "562       15.220         30.62          103.40      716.9          0.10480   \n",
       "563       20.920         25.09          143.00     1347.0          0.10990   \n",
       "564       21.560         22.39          142.00     1479.0          0.11100   \n",
       "565       20.130         28.25          131.20     1261.0          0.09780   \n",
       "566       16.600         28.08          108.30      858.1          0.08455   \n",
       "567       20.600         29.33          140.10     1265.0          0.11780   \n",
       "568        7.760         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760        0.300100             0.147100         0.2419   \n",
       "1             0.07864        0.086900             0.070170         0.1812   \n",
       "2             0.15990        0.197400             0.127900         0.2069   \n",
       "3             0.28390        0.241400             0.105200         0.2597   \n",
       "4             0.13280        0.198000             0.104300         0.1809   \n",
       "5             0.17000        0.157800             0.080890         0.2087   \n",
       "6             0.10900        0.112700             0.074000         0.1794   \n",
       "7             0.16450        0.093660             0.059850         0.2196   \n",
       "8             0.19320        0.185900             0.093530         0.2350   \n",
       "9             0.23960        0.227300             0.085430         0.2030   \n",
       "10            0.06669        0.032990             0.033230         0.1528   \n",
       "11            0.12920        0.099540             0.066060         0.1842   \n",
       "12            0.24580        0.206500             0.111800         0.2397   \n",
       "13            0.10020        0.099380             0.053640         0.1847   \n",
       "14            0.22930        0.212800             0.080250         0.2069   \n",
       "15            0.15950        0.163900             0.073640         0.2303   \n",
       "16            0.07200        0.073950             0.052590         0.1586   \n",
       "17            0.20220        0.172200             0.102800         0.2164   \n",
       "18            0.10270        0.147900             0.094980         0.1582   \n",
       "19            0.08129        0.066640             0.047810         0.1885   \n",
       "20            0.12700        0.045680             0.031100         0.1967   \n",
       "21            0.06492        0.029560             0.020760         0.1815   \n",
       "22            0.21350        0.207700             0.097560         0.2521   \n",
       "23            0.10220        0.109700             0.086320         0.1769   \n",
       "24            0.14570        0.152500             0.091700         0.1995   \n",
       "25            0.22760        0.222900             0.140100         0.3040   \n",
       "26            0.18680        0.142500             0.087830         0.2252   \n",
       "27            0.10660        0.149000             0.077310         0.1697   \n",
       "28            0.16970        0.168300             0.087510         0.1926   \n",
       "29            0.11570        0.098750             0.079530         0.1739   \n",
       "..                ...             ...                  ...            ...   \n",
       "539           0.11990        0.092520             0.013640         0.2037   \n",
       "540           0.11200        0.067370             0.025940         0.1818   \n",
       "541           0.12300        0.100900             0.038900         0.1872   \n",
       "542           0.07214        0.041050             0.030270         0.1840   \n",
       "543           0.06877        0.029870             0.032750         0.1628   \n",
       "544           0.10180        0.036880             0.023690         0.1620   \n",
       "545           0.06747        0.029740             0.024430         0.1664   \n",
       "546           0.04994        0.010120             0.005495         0.1885   \n",
       "547           0.08066        0.043580             0.024380         0.1669   \n",
       "548           0.05030        0.023370             0.009615         0.1580   \n",
       "549           0.06602        0.015480             0.008160         0.1976   \n",
       "550           0.04227        0.000000             0.000000         0.1661   \n",
       "551           0.08194        0.048240             0.022570         0.2030   \n",
       "552           0.04234        0.019970             0.014990         0.1539   \n",
       "553           0.05605        0.039960             0.012820         0.1692   \n",
       "554           0.05824        0.061950             0.023430         0.1566   \n",
       "555           0.07658        0.059990             0.027380         0.1593   \n",
       "556           0.07504        0.005025             0.011160         0.1791   \n",
       "557           0.04971        0.000000             0.000000         0.1742   \n",
       "558           0.13300        0.102900             0.037360         0.1454   \n",
       "559           0.10210        0.111200             0.041050         0.1388   \n",
       "560           0.11260        0.044620             0.043040         0.1537   \n",
       "561           0.03558        0.000000             0.000000         0.1060   \n",
       "562           0.20870        0.255000             0.094290         0.2128   \n",
       "563           0.22360        0.317400             0.147400         0.2149   \n",
       "564           0.11590        0.243900             0.138900         0.1726   \n",
       "565           0.10340        0.144000             0.097910         0.1752   \n",
       "566           0.10230        0.092510             0.053020         0.1590   \n",
       "567           0.27700        0.351400             0.152000         0.2397   \n",
       "568           0.04362        0.000000             0.000000         0.1587   \n",
       "\n",
       "     mean fractal dimension  radius error  texture error  perimeter error  \\\n",
       "0                   0.07871        1.0950         0.9053           8.5890   \n",
       "1                   0.05667        0.5435         0.7339           3.3980   \n",
       "2                   0.05999        0.7456         0.7869           4.5850   \n",
       "3                   0.09744        0.4956         1.1560           3.4450   \n",
       "4                   0.05883        0.7572         0.7813           5.4380   \n",
       "5                   0.07613        0.3345         0.8902           2.2170   \n",
       "6                   0.05742        0.4467         0.7732           3.1800   \n",
       "7                   0.07451        0.5835         1.3770           3.8560   \n",
       "8                   0.07389        0.3063         1.0020           2.4060   \n",
       "9                   0.08243        0.2976         1.5990           2.0390   \n",
       "10                  0.05697        0.3795         1.1870           2.4660   \n",
       "11                  0.06082        0.5058         0.9849           3.5640   \n",
       "12                  0.07800        0.9555         3.5680          11.0700   \n",
       "13                  0.05338        0.4033         1.0780           2.9030   \n",
       "14                  0.07682        0.2121         1.1690           2.0610   \n",
       "15                  0.07077        0.3700         1.0330           2.8790   \n",
       "16                  0.05922        0.4727         1.2400           3.1950   \n",
       "17                  0.07356        0.5692         1.0730           3.8540   \n",
       "18                  0.05395        0.7582         1.0170           5.8650   \n",
       "19                  0.05766        0.2699         0.7886           2.0580   \n",
       "20                  0.06811        0.1852         0.7477           1.3830   \n",
       "21                  0.06905        0.2773         0.9768           1.9090   \n",
       "22                  0.07032        0.4388         0.7096           3.3840   \n",
       "23                  0.05278        0.6917         1.1270           4.3030   \n",
       "24                  0.06330        0.8068         0.9017           5.4550   \n",
       "25                  0.07413        1.0460         0.9760           7.2760   \n",
       "26                  0.06924        0.2545         0.9832           2.1100   \n",
       "27                  0.05699        0.8529         1.8490           5.6320   \n",
       "28                  0.06540        0.4390         1.0120           3.4980   \n",
       "29                  0.06149        0.6003         0.8225           4.6550   \n",
       "..                      ...           ...            ...              ...   \n",
       "539                 0.07751        0.2196         1.4790           1.4450   \n",
       "540                 0.06782        0.2784         1.7680           1.6280   \n",
       "541                 0.06341        0.2542         1.0790           2.6150   \n",
       "542                 0.05680        0.3031         1.3850           2.1770   \n",
       "543                 0.05781        0.2351         1.5970           1.5390   \n",
       "544                 0.06688        0.2720         1.0470           2.0760   \n",
       "545                 0.05801        0.3460         1.3360           2.0660   \n",
       "546                 0.06201        0.2104         0.9670           1.3560   \n",
       "547                 0.06714        0.1144         1.0230           0.9887   \n",
       "548                 0.06235        0.2957         1.3630           2.0540   \n",
       "549                 0.06328        0.5196         1.9180           3.5640   \n",
       "550                 0.05948        0.3163         1.3040           2.1150   \n",
       "551                 0.06552        0.2800         1.4670           1.9940   \n",
       "552                 0.05637        0.2409         1.3670           1.4770   \n",
       "553                 0.06576        0.3013         1.8790           2.1210   \n",
       "554                 0.05708        0.2116         1.3600           1.5020   \n",
       "555                 0.06127        0.2199         2.2390           1.4370   \n",
       "556                 0.06331        0.2441         2.0900           1.6480   \n",
       "557                 0.06059        0.5375         2.9270           3.6180   \n",
       "558                 0.06147        0.2254         1.1080           2.2240   \n",
       "559                 0.06570        0.2388         2.9040           1.9360   \n",
       "560                 0.06171        0.3645         1.4920           2.8880   \n",
       "561                 0.05502        0.3141         3.8960           2.0410   \n",
       "562                 0.07152        0.2602         1.2050           2.3620   \n",
       "563                 0.06879        0.9622         1.0260           8.7580   \n",
       "564                 0.05623        1.1760         1.2560           7.6730   \n",
       "565                 0.05533        0.7655         2.4630           5.2030   \n",
       "566                 0.05648        0.4564         1.0750           3.4250   \n",
       "567                 0.07016        0.7260         1.5950           5.7720   \n",
       "568                 0.05884        0.3857         1.4280           2.5480   \n",
       "\n",
       "     area error  smoothness error  compactness error  concavity error  \\\n",
       "0       153.400          0.006399           0.049040         0.053730   \n",
       "1        74.080          0.005225           0.013080         0.018600   \n",
       "2        94.030          0.006150           0.040060         0.038320   \n",
       "3        27.230          0.009110           0.074580         0.056610   \n",
       "4        94.440          0.011490           0.024610         0.056880   \n",
       "5        27.190          0.007510           0.033450         0.036720   \n",
       "6        53.910          0.004314           0.013820         0.022540   \n",
       "7        50.960          0.008805           0.030290         0.024880   \n",
       "8        24.320          0.005731           0.035020         0.035530   \n",
       "9        23.940          0.007149           0.072170         0.077430   \n",
       "10       40.510          0.004029           0.009269         0.011010   \n",
       "11       54.160          0.005771           0.040610         0.027910   \n",
       "12      116.200          0.003139           0.082970         0.088900   \n",
       "13       36.580          0.009769           0.031260         0.050510   \n",
       "14       19.210          0.006429           0.059360         0.055010   \n",
       "15       32.550          0.005607           0.042400         0.047410   \n",
       "16       45.400          0.005718           0.011620         0.019980   \n",
       "17       54.180          0.007026           0.025010         0.031880   \n",
       "18      112.400          0.006494           0.018930         0.033910   \n",
       "19       23.560          0.008462           0.014600         0.023870   \n",
       "20       14.670          0.004097           0.018980         0.016980   \n",
       "21       15.700          0.009606           0.014320         0.019850   \n",
       "22       44.910          0.006789           0.053280         0.064460   \n",
       "23       93.990          0.004728           0.012590         0.017150   \n",
       "24      102.600          0.006048           0.018820         0.027410   \n",
       "25      111.400          0.008029           0.037990         0.037320   \n",
       "26       21.050          0.004452           0.030550         0.026810   \n",
       "27       93.540          0.010750           0.027220         0.050810   \n",
       "28       43.500          0.005233           0.030570         0.035760   \n",
       "29       61.100          0.005627           0.030330         0.034070   \n",
       "..          ...               ...                ...              ...   \n",
       "539      11.730          0.015470           0.064570         0.092520   \n",
       "540      20.860          0.012150           0.041120         0.055530   \n",
       "541      23.110          0.007138           0.046530         0.038290   \n",
       "542      27.410          0.004775           0.011720         0.019470   \n",
       "543      17.850          0.004973           0.013720         0.014980   \n",
       "544      23.120          0.006298           0.021720         0.026150   \n",
       "545      31.240          0.005868           0.020990         0.020210   \n",
       "546      12.970          0.007086           0.007247         0.010120   \n",
       "547       7.326          0.010270           0.030840         0.026130   \n",
       "548      18.240          0.007440           0.011230         0.023370   \n",
       "549      33.000          0.008263           0.018700         0.012770   \n",
       "550      20.670          0.009579           0.011040         0.000000   \n",
       "551      17.850          0.003495           0.030510         0.034450   \n",
       "552      18.760          0.008835           0.012330         0.013280   \n",
       "553      17.860          0.010940           0.018340         0.039960   \n",
       "554      16.830          0.008412           0.021530         0.038980   \n",
       "555      14.460          0.012050           0.027360         0.048040   \n",
       "556      16.800          0.012910           0.022220         0.004174   \n",
       "557      29.110          0.011590           0.011240         0.000000   \n",
       "558      19.540          0.004242           0.046390         0.065780   \n",
       "559      16.970          0.008200           0.029820         0.057380   \n",
       "560      29.840          0.007256           0.026780         0.020710   \n",
       "561      22.810          0.007594           0.008878         0.000000   \n",
       "562      22.650          0.004625           0.048440         0.073590   \n",
       "563     118.800          0.006399           0.043100         0.078450   \n",
       "564     158.700          0.010300           0.028910         0.051980   \n",
       "565      99.040          0.005769           0.024230         0.039500   \n",
       "566      48.550          0.005903           0.037310         0.047300   \n",
       "567      86.220          0.006522           0.061580         0.071170   \n",
       "568      19.150          0.007189           0.004660         0.000000   \n",
       "\n",
       "     concave points error  symmetry error  fractal dimension error  \\\n",
       "0                0.015870         0.03003                 0.006193   \n",
       "1                0.013400         0.01389                 0.003532   \n",
       "2                0.020580         0.02250                 0.004571   \n",
       "3                0.018670         0.05963                 0.009208   \n",
       "4                0.018850         0.01756                 0.005115   \n",
       "5                0.011370         0.02165                 0.005082   \n",
       "6                0.010390         0.01369                 0.002179   \n",
       "7                0.014480         0.01486                 0.005412   \n",
       "8                0.012260         0.02143                 0.003749   \n",
       "9                0.014320         0.01789                 0.010080   \n",
       "10               0.007591         0.01460                 0.003042   \n",
       "11               0.012820         0.02008                 0.004144   \n",
       "12               0.040900         0.04484                 0.012840   \n",
       "13               0.019920         0.02981                 0.003002   \n",
       "14               0.016280         0.01961                 0.008093   \n",
       "15               0.010900         0.01857                 0.005466   \n",
       "16               0.011090         0.01410                 0.002085   \n",
       "17               0.012970         0.01689                 0.004142   \n",
       "18               0.015210         0.01356                 0.001997   \n",
       "19               0.013150         0.01980                 0.002300   \n",
       "20               0.006490         0.01678                 0.002425   \n",
       "21               0.014210         0.02027                 0.002968   \n",
       "22               0.022520         0.03672                 0.004394   \n",
       "23               0.010380         0.01083                 0.001987   \n",
       "24               0.011300         0.01468                 0.002801   \n",
       "25               0.023970         0.02308                 0.007444   \n",
       "26               0.013520         0.01454                 0.003711   \n",
       "27               0.019110         0.02293                 0.004217   \n",
       "28               0.010830         0.01768                 0.002967   \n",
       "29               0.013540         0.01925                 0.003742   \n",
       "..                    ...             ...                      ...   \n",
       "539              0.013640         0.02105                 0.007551   \n",
       "540              0.014940         0.01840                 0.005512   \n",
       "541              0.011620         0.02068                 0.006111   \n",
       "542              0.012690         0.01870                 0.002626   \n",
       "543              0.009117         0.01724                 0.001343   \n",
       "544              0.009061         0.01490                 0.003599   \n",
       "545              0.009064         0.02087                 0.002583   \n",
       "546              0.005495         0.01560                 0.002606   \n",
       "547              0.010970         0.02277                 0.005890   \n",
       "548              0.009615         0.02203                 0.004154   \n",
       "549              0.005917         0.02466                 0.002977   \n",
       "550              0.000000         0.03004                 0.002228   \n",
       "551              0.010240         0.02912                 0.004723   \n",
       "552              0.009305         0.01897                 0.001726   \n",
       "553              0.012820         0.03759                 0.004623   \n",
       "554              0.007620         0.01695                 0.002801   \n",
       "555              0.017210         0.01843                 0.004938   \n",
       "556              0.007082         0.02572                 0.002278   \n",
       "557              0.000000         0.03004                 0.003324   \n",
       "558              0.016060         0.01638                 0.004406   \n",
       "559              0.012670         0.01488                 0.004738   \n",
       "560              0.016260         0.02080                 0.005304   \n",
       "561              0.000000         0.01989                 0.001773   \n",
       "562              0.016080         0.02137                 0.006142   \n",
       "563              0.026240         0.02057                 0.006213   \n",
       "564              0.024540         0.01114                 0.004239   \n",
       "565              0.016780         0.01898                 0.002498   \n",
       "566              0.015570         0.01318                 0.003892   \n",
       "567              0.016640         0.02324                 0.006185   \n",
       "568              0.000000         0.02676                 0.002783   \n",
       "\n",
       "     worst radius  worst texture  worst perimeter  worst area  \\\n",
       "0          25.380          17.33           184.60      2019.0   \n",
       "1          24.990          23.41           158.80      1956.0   \n",
       "2          23.570          25.53           152.50      1709.0   \n",
       "3          14.910          26.50            98.87       567.7   \n",
       "4          22.540          16.67           152.20      1575.0   \n",
       "5          15.470          23.75           103.40       741.6   \n",
       "6          22.880          27.66           153.20      1606.0   \n",
       "7          17.060          28.14           110.60       897.0   \n",
       "8          15.490          30.73           106.20       739.3   \n",
       "9          15.090          40.68            97.65       711.4   \n",
       "10         19.190          33.88           123.80      1150.0   \n",
       "11         20.420          27.28           136.50      1299.0   \n",
       "12         20.960          29.94           151.70      1332.0   \n",
       "13         16.840          27.66           112.00       876.5   \n",
       "14         15.030          32.01           108.80       697.7   \n",
       "15         17.460          37.13           124.10       943.2   \n",
       "16         19.070          30.88           123.40      1138.0   \n",
       "17         20.960          31.48           136.80      1315.0   \n",
       "18         27.320          30.88           186.80      2398.0   \n",
       "19         15.110          19.26            99.70       711.2   \n",
       "20         14.500          20.49            96.09       630.5   \n",
       "21         10.230          15.66            65.13       314.9   \n",
       "22         18.070          19.08           125.10       980.9   \n",
       "23         29.170          35.59           188.00      2615.0   \n",
       "24         26.460          31.56           177.00      2215.0   \n",
       "25         22.250          21.40           152.40      1461.0   \n",
       "26         17.620          33.21           122.40       896.9   \n",
       "27         21.310          27.26           139.90      1403.0   \n",
       "28         20.270          36.71           149.30      1269.0   \n",
       "29         20.010          19.52           134.90      1227.0   \n",
       "..            ...            ...              ...         ...   \n",
       "539         8.678          31.89            54.49       223.6   \n",
       "540        12.260          19.68            78.78       457.8   \n",
       "541        16.220          31.73           113.50       808.9   \n",
       "542        16.510          32.29           107.40       826.4   \n",
       "543        14.370          37.17            92.48       629.6   \n",
       "544        15.050          24.75            99.17       688.6   \n",
       "545        15.350          29.09            97.58       729.8   \n",
       "546        11.250          21.77            71.12       384.9   \n",
       "547        10.830          22.04            71.08       357.4   \n",
       "548        10.930          25.59            69.10       364.2   \n",
       "549        13.030          31.45            83.90       505.6   \n",
       "550        11.660          24.77            74.08       412.3   \n",
       "551        12.020          28.26            77.80       436.6   \n",
       "552        13.870          36.00            88.10       594.7   \n",
       "553         9.845          25.05            62.86       295.8   \n",
       "554        13.890          35.74            88.84       595.7   \n",
       "555        10.840          34.91            69.57       357.6   \n",
       "556        10.650          22.88            67.88       347.3   \n",
       "557        10.490          34.24            66.50       330.6   \n",
       "558        15.480          27.27           105.90       733.5   \n",
       "559        12.480          37.16            82.28       474.2   \n",
       "560        15.300          33.17           100.20       706.7   \n",
       "561        11.920          38.30            75.19       439.6   \n",
       "562        17.520          42.79           128.70       915.0   \n",
       "563        24.290          29.41           179.10      1819.0   \n",
       "564        25.450          26.40           166.10      2027.0   \n",
       "565        23.690          38.25           155.00      1731.0   \n",
       "566        18.980          34.12           126.70      1124.0   \n",
       "567        25.740          39.42           184.60      1821.0   \n",
       "568         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560          0.71190   \n",
       "1             0.12380            0.18660          0.24160   \n",
       "2             0.14440            0.42450          0.45040   \n",
       "3             0.20980            0.86630          0.68690   \n",
       "4             0.13740            0.20500          0.40000   \n",
       "5             0.17910            0.52490          0.53550   \n",
       "6             0.14420            0.25760          0.37840   \n",
       "7             0.16540            0.36820          0.26780   \n",
       "8             0.17030            0.54010          0.53900   \n",
       "9             0.18530            1.05800          1.10500   \n",
       "10            0.11810            0.15510          0.14590   \n",
       "11            0.13960            0.56090          0.39650   \n",
       "12            0.10370            0.39030          0.36390   \n",
       "13            0.11310            0.19240          0.23220   \n",
       "14            0.16510            0.77250          0.69430   \n",
       "15            0.16780            0.65770          0.70260   \n",
       "16            0.14640            0.18710          0.29140   \n",
       "17            0.17890            0.42330          0.47840   \n",
       "18            0.15120            0.31500          0.53720   \n",
       "19            0.14400            0.17730          0.23900   \n",
       "20            0.13120            0.27760          0.18900   \n",
       "21            0.13240            0.11480          0.08867   \n",
       "22            0.13900            0.59540          0.63050   \n",
       "23            0.14010            0.26000          0.31550   \n",
       "24            0.18050            0.35780          0.46950   \n",
       "25            0.15450            0.39490          0.38530   \n",
       "26            0.15250            0.66430          0.55390   \n",
       "27            0.13380            0.21170          0.34460   \n",
       "28            0.16410            0.61100          0.63350   \n",
       "29            0.12550            0.28120          0.24890   \n",
       "..                ...                ...              ...   \n",
       "539           0.15960            0.30640          0.33930   \n",
       "540           0.13450            0.21180          0.17970   \n",
       "541           0.13400            0.42020          0.40400   \n",
       "542           0.10600            0.13760          0.16110   \n",
       "543           0.10720            0.13810          0.10620   \n",
       "544           0.12640            0.20370          0.13770   \n",
       "545           0.12160            0.15170          0.10490   \n",
       "546           0.12850            0.08842          0.04384   \n",
       "547           0.14610            0.22460          0.17830   \n",
       "548           0.11990            0.09546          0.09350   \n",
       "549           0.12040            0.16330          0.06194   \n",
       "550           0.10010            0.07348          0.00000   \n",
       "551           0.10870            0.17820          0.15640   \n",
       "552           0.12340            0.10640          0.08653   \n",
       "553           0.11030            0.08298          0.07993   \n",
       "554           0.12270            0.16200          0.24390   \n",
       "555           0.13840            0.17100          0.20000   \n",
       "556           0.12650            0.12000          0.01005   \n",
       "557           0.10730            0.07158          0.00000   \n",
       "558           0.10260            0.31710          0.36620   \n",
       "559           0.12980            0.25170          0.36300   \n",
       "560           0.12410            0.22640          0.13260   \n",
       "561           0.09267            0.05494          0.00000   \n",
       "562           0.14170            0.79170          1.17000   \n",
       "563           0.14070            0.41860          0.65990   \n",
       "564           0.14100            0.21130          0.41070   \n",
       "565           0.11660            0.19220          0.32150   \n",
       "566           0.11390            0.30940          0.34030   \n",
       "567           0.16500            0.86810          0.93870   \n",
       "568           0.08996            0.06444          0.00000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                 0.26540          0.4601                  0.11890  \n",
       "1                 0.18600          0.2750                  0.08902  \n",
       "2                 0.24300          0.3613                  0.08758  \n",
       "3                 0.25750          0.6638                  0.17300  \n",
       "4                 0.16250          0.2364                  0.07678  \n",
       "5                 0.17410          0.3985                  0.12440  \n",
       "6                 0.19320          0.3063                  0.08368  \n",
       "7                 0.15560          0.3196                  0.11510  \n",
       "8                 0.20600          0.4378                  0.10720  \n",
       "9                 0.22100          0.4366                  0.20750  \n",
       "10                0.09975          0.2948                  0.08452  \n",
       "11                0.18100          0.3792                  0.10480  \n",
       "12                0.17670          0.3176                  0.10230  \n",
       "13                0.11190          0.2809                  0.06287  \n",
       "14                0.22080          0.3596                  0.14310  \n",
       "15                0.17120          0.4218                  0.13410  \n",
       "16                0.16090          0.3029                  0.08216  \n",
       "17                0.20730          0.3706                  0.11420  \n",
       "18                0.23880          0.2768                  0.07615  \n",
       "19                0.12880          0.2977                  0.07259  \n",
       "20                0.07283          0.3184                  0.08183  \n",
       "21                0.06227          0.2450                  0.07773  \n",
       "22                0.23930          0.4667                  0.09946  \n",
       "23                0.20090          0.2822                  0.07526  \n",
       "24                0.20950          0.3613                  0.09564  \n",
       "25                0.25500          0.4066                  0.10590  \n",
       "26                0.27010          0.4264                  0.12750  \n",
       "27                0.14900          0.2341                  0.07421  \n",
       "28                0.20240          0.4027                  0.09876  \n",
       "29                0.14560          0.2756                  0.07919  \n",
       "..                    ...             ...                      ...  \n",
       "539               0.05000          0.2790                  0.10660  \n",
       "540               0.06918          0.2329                  0.08134  \n",
       "541               0.12050          0.3187                  0.10230  \n",
       "542               0.10950          0.2722                  0.06956  \n",
       "543               0.07958          0.2473                  0.06443  \n",
       "544               0.06845          0.2249                  0.08492  \n",
       "545               0.07174          0.2642                  0.06953  \n",
       "546               0.02381          0.2681                  0.07399  \n",
       "547               0.08333          0.2691                  0.09479  \n",
       "548               0.03846          0.2552                  0.07920  \n",
       "549               0.03264          0.3059                  0.07626  \n",
       "550               0.00000          0.2458                  0.06592  \n",
       "551               0.06413          0.3169                  0.08032  \n",
       "552               0.06498          0.2407                  0.06484  \n",
       "553               0.02564          0.2435                  0.07393  \n",
       "554               0.06493          0.2372                  0.07242  \n",
       "555               0.09127          0.2226                  0.08283  \n",
       "556               0.02232          0.2262                  0.06742  \n",
       "557               0.00000          0.2475                  0.06969  \n",
       "558               0.11050          0.2258                  0.08004  \n",
       "559               0.09653          0.2112                  0.08732  \n",
       "560               0.10480          0.2250                  0.08321  \n",
       "561               0.00000          0.1566                  0.05905  \n",
       "562               0.23560          0.4089                  0.14090  \n",
       "563               0.25420          0.2929                  0.09873  \n",
       "564               0.22160          0.2060                  0.07115  \n",
       "565               0.16280          0.2572                  0.06637  \n",
       "566               0.14180          0.2218                  0.07820  \n",
       "567               0.26500          0.4087                  0.12400  \n",
       "568               0.00000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df6.drop('target',axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     0\n",
       "17     0\n",
       "18     0\n",
       "19     1\n",
       "20     1\n",
       "21     1\n",
       "22     0\n",
       "23     0\n",
       "24     0\n",
       "25     0\n",
       "26     0\n",
       "27     0\n",
       "28     0\n",
       "29     0\n",
       "      ..\n",
       "539    1\n",
       "540    1\n",
       "541    1\n",
       "542    1\n",
       "543    1\n",
       "544    1\n",
       "545    1\n",
       "546    1\n",
       "547    1\n",
       "548    1\n",
       "549    1\n",
       "550    1\n",
       "551    1\n",
       "552    1\n",
       "553    1\n",
       "554    1\n",
       "555    1\n",
       "556    1\n",
       "557    1\n",
       "558    1\n",
       "559    1\n",
       "560    1\n",
       "561    1\n",
       "562    0\n",
       "563    0\n",
       "564    0\n",
       "565    0\n",
       "566    0\n",
       "567    0\n",
       "568    1\n",
       "Name: target, Length: 569, dtype: int32"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=df6['target']\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=KNeighborsClassifier()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        63\n",
      "           1       0.96      0.95      0.96       108\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.94      0.95      0.94       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-FOLD CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "df=pd.read_csv(\"E:\\python\\csv files\\Social_Network_Ads.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['Age','EstimatedSalary']]\n",
    "y = df['Purchased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,random_state =5)\n",
    "knnclassifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knnclassifier.fit(x_train,y_train)\n",
    "y_pred = knnclassifier.predict(x_test)\n",
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>46</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>28</td>\n",
       "      <td>44000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>39</td>\n",
       "      <td>106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>35</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  EstimatedSalary\n",
       "24    46            23000\n",
       "33    28            44000\n",
       "396   51            23000\n",
       "273   39           106000\n",
       "246   35            50000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,random_state =2)\n",
    "knnclassifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knnclassifier.fit(x_train,y_train)\n",
    "y_pred = knnclassifier.predict(x_test)\n",
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>38</td>\n",
       "      <td>71000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>37</td>\n",
       "      <td>52000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>38</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>41</td>\n",
       "      <td>72000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  EstimatedSalary\n",
       "276   38            71000\n",
       "251   37            52000\n",
       "29    31            18000\n",
       "109   38            80000\n",
       "244   41            72000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70731707 0.92682927 0.80487805 0.925      0.75       0.625\n",
      " 0.725      0.82051282 0.71794872 0.76923077]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "knnclassifier = KNeighborsClassifier(n_neighbors=5)\n",
    "print(cross_val_score(knnclassifier, x, y, cv=10, scoring ='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777171669793621\n"
     ]
    }
   ],
   "source": [
    "# taking the mean of above value\n",
    "from sklearn.model_selection import cross_val_score\n",
    "knnclassifier = KNeighborsClassifier(n_neighbors=5)\n",
    "print(cross_val_score(knnclassifier, x, y, cv=10, scoring ='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    }
   ],
   "source": [
    "# taking the min of above value\n",
    "from sklearn.model_selection import cross_val_score\n",
    "knnclassifier = KNeighborsClassifier(n_neighbors=5)\n",
    "print(cross_val_score(knnclassifier, x, y, cv=10, scoring ='accuracy').min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926829268292683\n"
     ]
    }
   ],
   "source": [
    "# taking the max of above value\n",
    "from sklearn.model_selection import cross_val_score\n",
    "knnclassifier = KNeighborsClassifier(n_neighbors=5)\n",
    "print(cross_val_score(knnclassifier, x, y, cv=10, scoring ='accuracy').max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68292683 0.63414634 0.63414634 0.65       0.65       0.65\n",
      " 0.65       0.64102564 0.64102564 0.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "print (cross_val_score(logreg, x, y, cv=10, scoring = 'accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6499937460913072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "print (cross_val_score(logreg, x, y, cv=10, scoring = 'accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID SEARCHCV #HERE WE USE SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "dataset=pd.read_csv(\"E:\\python\\csv files\\Social_Network_Ads.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, [2, 3]].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 5)\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Kernel SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Applying Grid Search to find the best model and the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters is a list of dictionary forms\n",
    "parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},  # c is the penalty parameter\n",
    "              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,  # all the combination of different parameters we can have within SVC\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1) # all cpu cores will be used for executing perticular model\n",
    "grid_search = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = grid_search.best_score_\n",
    "accuracy # it is grid search accuracy not model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.3, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.3, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier = SVC(kernel = 'rbf', gamma=0.3, C=10)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOMIZED SEARCH_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is used for for selecting best type parameter any classification parameter. it helps to select hyper parameter\n",
    "# go through grid search cv-SVM, it is a very very slow compared randimized search cv and it is worked on very low number of hyper \n",
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"E:\\python\\csv files\\Social_Network_Ads.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    19,  19000],\n",
       "       [    35,  20000],\n",
       "       [    26,  43000],\n",
       "       [    27,  57000],\n",
       "       [    19,  76000],\n",
       "       [    27,  58000],\n",
       "       [    27,  84000],\n",
       "       [    32, 150000],\n",
       "       [    25,  33000],\n",
       "       [    35,  65000],\n",
       "       [    26,  80000],\n",
       "       [    26,  52000],\n",
       "       [    20,  86000],\n",
       "       [    32,  18000],\n",
       "       [    18,  82000],\n",
       "       [    29,  80000],\n",
       "       [    47,  25000],\n",
       "       [    45,  26000],\n",
       "       [    46,  28000],\n",
       "       [    48,  29000],\n",
       "       [    45,  22000],\n",
       "       [    47,  49000],\n",
       "       [    48,  41000],\n",
       "       [    45,  22000],\n",
       "       [    46,  23000],\n",
       "       [    47,  20000],\n",
       "       [    49,  28000],\n",
       "       [    47,  30000],\n",
       "       [    29,  43000],\n",
       "       [    31,  18000],\n",
       "       [    31,  74000],\n",
       "       [    27, 137000],\n",
       "       [    21,  16000],\n",
       "       [    28,  44000],\n",
       "       [    27,  90000],\n",
       "       [    35,  27000],\n",
       "       [    33,  28000],\n",
       "       [    30,  49000],\n",
       "       [    26,  72000],\n",
       "       [    27,  31000],\n",
       "       [    27,  17000],\n",
       "       [    33,  51000],\n",
       "       [    35, 108000],\n",
       "       [    30,  15000],\n",
       "       [    28,  84000],\n",
       "       [    23,  20000],\n",
       "       [    25,  79000],\n",
       "       [    27,  54000],\n",
       "       [    30, 135000],\n",
       "       [    31,  89000],\n",
       "       [    24,  32000],\n",
       "       [    18,  44000],\n",
       "       [    29,  83000],\n",
       "       [    35,  23000],\n",
       "       [    27,  58000],\n",
       "       [    24,  55000],\n",
       "       [    23,  48000],\n",
       "       [    28,  79000],\n",
       "       [    22,  18000],\n",
       "       [    32, 117000],\n",
       "       [    27,  20000],\n",
       "       [    25,  87000],\n",
       "       [    23,  66000],\n",
       "       [    32, 120000],\n",
       "       [    59,  83000],\n",
       "       [    24,  58000],\n",
       "       [    24,  19000],\n",
       "       [    23,  82000],\n",
       "       [    22,  63000],\n",
       "       [    31,  68000],\n",
       "       [    25,  80000],\n",
       "       [    24,  27000],\n",
       "       [    20,  23000],\n",
       "       [    33, 113000],\n",
       "       [    32,  18000],\n",
       "       [    34, 112000],\n",
       "       [    18,  52000],\n",
       "       [    22,  27000],\n",
       "       [    28,  87000],\n",
       "       [    26,  17000],\n",
       "       [    30,  80000],\n",
       "       [    39,  42000],\n",
       "       [    20,  49000],\n",
       "       [    35,  88000],\n",
       "       [    30,  62000],\n",
       "       [    31, 118000],\n",
       "       [    24,  55000],\n",
       "       [    28,  85000],\n",
       "       [    26,  81000],\n",
       "       [    35,  50000],\n",
       "       [    22,  81000],\n",
       "       [    30, 116000],\n",
       "       [    26,  15000],\n",
       "       [    29,  28000],\n",
       "       [    29,  83000],\n",
       "       [    35,  44000],\n",
       "       [    35,  25000],\n",
       "       [    28, 123000],\n",
       "       [    35,  73000],\n",
       "       [    28,  37000],\n",
       "       [    27,  88000],\n",
       "       [    28,  59000],\n",
       "       [    32,  86000],\n",
       "       [    33, 149000],\n",
       "       [    19,  21000],\n",
       "       [    21,  72000],\n",
       "       [    26,  35000],\n",
       "       [    27,  89000],\n",
       "       [    26,  86000],\n",
       "       [    38,  80000],\n",
       "       [    39,  71000],\n",
       "       [    37,  71000],\n",
       "       [    38,  61000],\n",
       "       [    37,  55000],\n",
       "       [    42,  80000],\n",
       "       [    40,  57000],\n",
       "       [    35,  75000],\n",
       "       [    36,  52000],\n",
       "       [    40,  59000],\n",
       "       [    41,  59000],\n",
       "       [    36,  75000],\n",
       "       [    37,  72000],\n",
       "       [    40,  75000],\n",
       "       [    35,  53000],\n",
       "       [    41,  51000],\n",
       "       [    39,  61000],\n",
       "       [    42,  65000],\n",
       "       [    26,  32000],\n",
       "       [    30,  17000],\n",
       "       [    26,  84000],\n",
       "       [    31,  58000],\n",
       "       [    33,  31000],\n",
       "       [    30,  87000],\n",
       "       [    21,  68000],\n",
       "       [    28,  55000],\n",
       "       [    23,  63000],\n",
       "       [    20,  82000],\n",
       "       [    30, 107000],\n",
       "       [    28,  59000],\n",
       "       [    19,  25000],\n",
       "       [    19,  85000],\n",
       "       [    18,  68000],\n",
       "       [    35,  59000],\n",
       "       [    30,  89000],\n",
       "       [    34,  25000],\n",
       "       [    24,  89000],\n",
       "       [    27,  96000],\n",
       "       [    41,  30000],\n",
       "       [    29,  61000],\n",
       "       [    20,  74000],\n",
       "       [    26,  15000],\n",
       "       [    41,  45000],\n",
       "       [    31,  76000],\n",
       "       [    36,  50000],\n",
       "       [    40,  47000],\n",
       "       [    31,  15000],\n",
       "       [    46,  59000],\n",
       "       [    29,  75000],\n",
       "       [    26,  30000],\n",
       "       [    32, 135000],\n",
       "       [    32, 100000],\n",
       "       [    25,  90000],\n",
       "       [    37,  33000],\n",
       "       [    35,  38000],\n",
       "       [    33,  69000],\n",
       "       [    18,  86000],\n",
       "       [    22,  55000],\n",
       "       [    35,  71000],\n",
       "       [    29, 148000],\n",
       "       [    29,  47000],\n",
       "       [    21,  88000],\n",
       "       [    34, 115000],\n",
       "       [    26, 118000],\n",
       "       [    34,  43000],\n",
       "       [    34,  72000],\n",
       "       [    23,  28000],\n",
       "       [    35,  47000],\n",
       "       [    25,  22000],\n",
       "       [    24,  23000],\n",
       "       [    31,  34000],\n",
       "       [    26,  16000],\n",
       "       [    31,  71000],\n",
       "       [    32, 117000],\n",
       "       [    33,  43000],\n",
       "       [    33,  60000],\n",
       "       [    31,  66000],\n",
       "       [    20,  82000],\n",
       "       [    33,  41000],\n",
       "       [    35,  72000],\n",
       "       [    28,  32000],\n",
       "       [    24,  84000],\n",
       "       [    19,  26000],\n",
       "       [    29,  43000],\n",
       "       [    19,  70000],\n",
       "       [    28,  89000],\n",
       "       [    34,  43000],\n",
       "       [    30,  79000],\n",
       "       [    20,  36000],\n",
       "       [    26,  80000],\n",
       "       [    35,  22000],\n",
       "       [    35,  39000],\n",
       "       [    49,  74000],\n",
       "       [    39, 134000],\n",
       "       [    41,  71000],\n",
       "       [    58, 101000],\n",
       "       [    47,  47000],\n",
       "       [    55, 130000],\n",
       "       [    52, 114000],\n",
       "       [    40, 142000],\n",
       "       [    46,  22000],\n",
       "       [    48,  96000],\n",
       "       [    52, 150000],\n",
       "       [    59,  42000],\n",
       "       [    35,  58000],\n",
       "       [    47,  43000],\n",
       "       [    60, 108000],\n",
       "       [    49,  65000],\n",
       "       [    40,  78000],\n",
       "       [    46,  96000],\n",
       "       [    59, 143000],\n",
       "       [    41,  80000],\n",
       "       [    35,  91000],\n",
       "       [    37, 144000],\n",
       "       [    60, 102000],\n",
       "       [    35,  60000],\n",
       "       [    37,  53000],\n",
       "       [    36, 126000],\n",
       "       [    56, 133000],\n",
       "       [    40,  72000],\n",
       "       [    42,  80000],\n",
       "       [    35, 147000],\n",
       "       [    39,  42000],\n",
       "       [    40, 107000],\n",
       "       [    49,  86000],\n",
       "       [    38, 112000],\n",
       "       [    46,  79000],\n",
       "       [    40,  57000],\n",
       "       [    37,  80000],\n",
       "       [    46,  82000],\n",
       "       [    53, 143000],\n",
       "       [    42, 149000],\n",
       "       [    38,  59000],\n",
       "       [    50,  88000],\n",
       "       [    56, 104000],\n",
       "       [    41,  72000],\n",
       "       [    51, 146000],\n",
       "       [    35,  50000],\n",
       "       [    57, 122000],\n",
       "       [    41,  52000],\n",
       "       [    35,  97000],\n",
       "       [    44,  39000],\n",
       "       [    37,  52000],\n",
       "       [    48, 134000],\n",
       "       [    37, 146000],\n",
       "       [    50,  44000],\n",
       "       [    52,  90000],\n",
       "       [    41,  72000],\n",
       "       [    40,  57000],\n",
       "       [    58,  95000],\n",
       "       [    45, 131000],\n",
       "       [    35,  77000],\n",
       "       [    36, 144000],\n",
       "       [    55, 125000],\n",
       "       [    35,  72000],\n",
       "       [    48,  90000],\n",
       "       [    42, 108000],\n",
       "       [    40,  75000],\n",
       "       [    37,  74000],\n",
       "       [    47, 144000],\n",
       "       [    40,  61000],\n",
       "       [    43, 133000],\n",
       "       [    59,  76000],\n",
       "       [    60,  42000],\n",
       "       [    39, 106000],\n",
       "       [    57,  26000],\n",
       "       [    57,  74000],\n",
       "       [    38,  71000],\n",
       "       [    49,  88000],\n",
       "       [    52,  38000],\n",
       "       [    50,  36000],\n",
       "       [    59,  88000],\n",
       "       [    35,  61000],\n",
       "       [    37,  70000],\n",
       "       [    52,  21000],\n",
       "       [    48, 141000],\n",
       "       [    37,  93000],\n",
       "       [    37,  62000],\n",
       "       [    48, 138000],\n",
       "       [    41,  79000],\n",
       "       [    37,  78000],\n",
       "       [    39, 134000],\n",
       "       [    49,  89000],\n",
       "       [    55,  39000],\n",
       "       [    37,  77000],\n",
       "       [    35,  57000],\n",
       "       [    36,  63000],\n",
       "       [    42,  73000],\n",
       "       [    43, 112000],\n",
       "       [    45,  79000],\n",
       "       [    46, 117000],\n",
       "       [    58,  38000],\n",
       "       [    48,  74000],\n",
       "       [    37, 137000],\n",
       "       [    37,  79000],\n",
       "       [    40,  60000],\n",
       "       [    42,  54000],\n",
       "       [    51, 134000],\n",
       "       [    47, 113000],\n",
       "       [    36, 125000],\n",
       "       [    38,  50000],\n",
       "       [    42,  70000],\n",
       "       [    39,  96000],\n",
       "       [    38,  50000],\n",
       "       [    49, 141000],\n",
       "       [    39,  79000],\n",
       "       [    39,  75000],\n",
       "       [    54, 104000],\n",
       "       [    35,  55000],\n",
       "       [    45,  32000],\n",
       "       [    36,  60000],\n",
       "       [    52, 138000],\n",
       "       [    53,  82000],\n",
       "       [    41,  52000],\n",
       "       [    48,  30000],\n",
       "       [    48, 131000],\n",
       "       [    41,  60000],\n",
       "       [    41,  72000],\n",
       "       [    42,  75000],\n",
       "       [    36, 118000],\n",
       "       [    47, 107000],\n",
       "       [    38,  51000],\n",
       "       [    48, 119000],\n",
       "       [    42,  65000],\n",
       "       [    40,  65000],\n",
       "       [    57,  60000],\n",
       "       [    36,  54000],\n",
       "       [    58, 144000],\n",
       "       [    35,  79000],\n",
       "       [    38,  55000],\n",
       "       [    39, 122000],\n",
       "       [    53, 104000],\n",
       "       [    35,  75000],\n",
       "       [    38,  65000],\n",
       "       [    47,  51000],\n",
       "       [    47, 105000],\n",
       "       [    41,  63000],\n",
       "       [    53,  72000],\n",
       "       [    54, 108000],\n",
       "       [    39,  77000],\n",
       "       [    38,  61000],\n",
       "       [    38, 113000],\n",
       "       [    37,  75000],\n",
       "       [    42,  90000],\n",
       "       [    37,  57000],\n",
       "       [    36,  99000],\n",
       "       [    60,  34000],\n",
       "       [    54,  70000],\n",
       "       [    41,  72000],\n",
       "       [    40,  71000],\n",
       "       [    42,  54000],\n",
       "       [    43, 129000],\n",
       "       [    53,  34000],\n",
       "       [    47,  50000],\n",
       "       [    42,  79000],\n",
       "       [    42, 104000],\n",
       "       [    59,  29000],\n",
       "       [    58,  47000],\n",
       "       [    46,  88000],\n",
       "       [    38,  71000],\n",
       "       [    54,  26000],\n",
       "       [    60,  46000],\n",
       "       [    60,  83000],\n",
       "       [    39,  73000],\n",
       "       [    59, 130000],\n",
       "       [    37,  80000],\n",
       "       [    46,  32000],\n",
       "       [    46,  74000],\n",
       "       [    42,  53000],\n",
       "       [    41,  87000],\n",
       "       [    58,  23000],\n",
       "       [    42,  64000],\n",
       "       [    48,  33000],\n",
       "       [    44, 139000],\n",
       "       [    49,  28000],\n",
       "       [    57,  33000],\n",
       "       [    56,  60000],\n",
       "       [    49,  39000],\n",
       "       [    39,  71000],\n",
       "       [    47,  34000],\n",
       "       [    48,  35000],\n",
       "       [    48,  33000],\n",
       "       [    47,  23000],\n",
       "       [    45,  45000],\n",
       "       [    60,  42000],\n",
       "       [    39,  59000],\n",
       "       [    46,  41000],\n",
       "       [    51,  23000],\n",
       "       [    50,  20000],\n",
       "       [    36,  33000],\n",
       "       [    49,  36000]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=df.iloc[:,[2,3]].values\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Age  EstimatedSalary  Purchased\n",
       "0  15624510   19            19000          0\n",
       "1  15810944   35            20000          0\n",
       "2  15668575   26            43000          0\n",
       "3  15603246   27            57000          0\n",
       "4  15804002   19            76000          0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here Gender column is not required so we can drop\n",
    "df1=df.drop(['Gender'],axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(df1)\n",
    "data=scaler.transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EstimatedSalary  Purchased\n",
       "0            19000          0\n",
       "1            20000          0\n",
       "2            43000          0\n",
       "3            57000          0\n",
       "4            76000          0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df1.iloc[:,[2,3]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Purchased\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df.iloc[:,[4]]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, Y, test_size=0.3,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomized search_cv is used to determine the n_estimators(how many trees), criterion (entropy or gini) and random_state\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "model=RandomForestClassifier(n_jobs=-1)\n",
    "hyp_param={'max_depth':[3,5,10,None],\n",
    "              'n_estimators':[10,100,200,300,400,500],\n",
    "              'max_features':randint(1,3),\n",
    "               'criterion':['gini','entropy'],\n",
    "               'bootstrap':[True,False],\n",
    "               'min_samples_leaf':randint(1,4)\n",
    "          }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypertuning_rscv(model,p_distr,nbr_iter,X,y):\n",
    "    rdmsearch = RandomizedSearchCV(model, param_distributions=p_distr,\n",
    "                                  n_jobs=-1, n_iter=nbr_iter, cv=9) # cross validation\n",
    "    #CV = Cross-Validation ( here using Stratified KFold CV)\n",
    "    rdmsearch.fit(X,y)\n",
    "    ht_params = rdmsearch.best_params_\n",
    "    ht_score = rdmsearch.best_score_\n",
    "    return ht_params, ht_score\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:714: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "rf_parameters, rf_ht_score = hypertuning_rscv(model,hyp_param, 40,X,y) # 40 is the number of iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_parameters # these are the hyper parameters we can select random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_ht_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=5, max_features=2, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=RandomForestClassifier(n_jobs=-1, \n",
    "        n_estimators=10,bootstrap= True,criterion='entropy',max_depth=5,max_features=2,min_samples_leaf= 1)\n",
    "classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "n_estimators = number of trees in the foreset\n",
    "max_features = max number of features considered for splitting a node\n",
    "max_depth = max number of levels in each decision tree\n",
    "min_samples_split = min number of data points placed in a node before the node is split\n",
    "min_samples_leaf = min number of data points allowed in a leaf node\n",
    "bootstrap = method for sampling data points (with or without replacement)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79,  0],\n",
       "       [ 0, 41]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "## Cross Validation good for selecting models\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val=cross_val_score(claasifier,X,y,cv=10,scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n",
    "accuracy_score=accuracy_score(y_test,y_pred)\n",
    "accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEJ\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\TEJ\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\TEJ\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris=load_iris()\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(iris.data,columns=['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)','petal width (cm)'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame(iris.target,columns=[\"target\"])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.concat([df,df1],axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df2.drop('target',axis=1))\n",
    "\n",
    "scaled_features = scaler.transform(df2.drop('target',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.019004</td>\n",
       "      <td>-1.340227</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.143017</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>-1.340227</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.385353</td>\n",
       "      <td>0.328414</td>\n",
       "      <td>-1.397064</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.506521</td>\n",
       "      <td>0.098217</td>\n",
       "      <td>-1.283389</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.021849</td>\n",
       "      <td>1.249201</td>\n",
       "      <td>-1.340227</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0          -0.900681          1.019004          -1.340227         -1.315444\n",
       "1          -1.143017         -0.131979          -1.340227         -1.315444\n",
       "2          -1.385353          0.328414          -1.397064         -1.315444\n",
       "3          -1.506521          0.098217          -1.283389         -1.315444\n",
       "4          -1.021849          1.249201          -1.340227         -1.315444"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat = pd.DataFrame(scaled_features,columns=df2.columns[:-1]) # skip last column and bring all columns\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features,df2['target'],\n",
    "                                                    test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "\n",
    "# Will take some time\n",
    "for i in range(1,40):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH K=17\n",
      "\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  2 15]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.94      0.94        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOW WITH K=17\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=17)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print('WITH K=17')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters of knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris=load_iris()\n",
    "iris\n",
    "\n",
    "\n",
    "df=pd.DataFrame(iris.data,columns=['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)','petal width (cm)'])\n",
    "df.head()\n",
    "\n",
    "df1=pd.DataFrame(iris.target,columns=[\"target\"])\n",
    "df1.head()\n",
    "\n",
    "\n",
    "df2=pd.concat([df,df1],axis=1)\n",
    "df2.head()\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df2.drop('target',axis=1))\n",
    "\n",
    "scaled_features = scaler.transform(df2.drop('target',axis=1))\n",
    "\n",
    "\n",
    "\n",
    "df_feat = pd.DataFrame(scaled_features,columns=df2.columns[:-1]) # skip last column and bring all columns\n",
    "df_feat.head()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features,df2['target'],\n",
    "                                                    test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0]\n",
      " [ 0 16  3]\n",
      " [ 0  0 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      0.84      0.91        19\n",
      "           2       0.82      1.00      0.90        14\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.95      0.94        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOW TO FIND OUTLIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset= [11,10,12,14,12,15,14,13,15,102,12,14,17,19,107, 10,13,12,14,12,108,12,11,14,13,15,10,15,12,10,14,13,15,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting outlier using Z score\n",
    "Using Z score\n",
    "Formula for Z score = (Observation — Mean)/Standard Deviation\n",
    "\n",
    "z = (X — μ) / σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers=[]\n",
    "def detect_outliers(data):\n",
    "    \n",
    "    threshold=3 #outside the 3rd range range of SD is considerwd as outliers\n",
    "    mean = np.mean(data)\n",
    "    std =np.std(data)\n",
    "    \n",
    "    \n",
    "    for i in data:\n",
    "        z_score= (i - mean)/std \n",
    "        if np.abs(z_score) > threshold:\n",
    "            outliers.append(i)\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[102, 107, 108]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_pt=detect_outliers(dataset)\n",
    "outlier_pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InterQuantile Range\n",
    "75%- 25% values in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 17,\n",
       " 19,\n",
       " 102,\n",
       " 107,\n",
       " 108]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Perform all the steps of IQR\n",
    "sorted(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile1, quantile3= np.percentile(dataset,[25,75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 15.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(quantile1,quantile3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "## Find the IQR\n",
    "\n",
    "iqr_value=quantile3-quantile1\n",
    "print(iqr_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the lower bound value and the higher bound value\n",
    "\n",
    "lower_bound_val = quantile1 -(1.5 * iqr_value) \n",
    "upper_bound_val = quantile3 +(1.5 * iqr_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5 19.5\n"
     ]
    }
   ],
   "source": [
    "print(lower_bound_val,upper_bound_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEJ\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10b8dd9c18>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
